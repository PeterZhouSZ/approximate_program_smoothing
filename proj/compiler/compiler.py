
import sys
import copy
import numpy
import string
import pprint
import hashlib
import subprocess
import os, os.path
import bandlimit_poly
from interval_util import *     # pyinterval module (interval) and utility functions
import util
import traceback
import math
import functools
import time
import inspect
import random
import shutil
import glob
import multiprocessing
import atexit
import filelock

sys.setrecursionlimit(10**6)

builtin_min = min
builtin_max = max

assert sys.version_info[0] == 3, 'requires Python 3'

MAX_SIGMA_RATIO = 0.5           # Maximum sigma value relative to range of unknown input array: 1.0 means same sigma as range.

int_types = (int, numpy.int8, numpy.int16, numpy.int32, numpy.int64)
float_types = (float, numpy.float32, numpy.float64)

extra_verbose = False
debug_prints  = False

DEFAULT_VERBOSE = 0                         # Verbosity level, 0=none, 1=some, 2=more.
DEFAULT_ARGUMENT_ARRAY_NAME = 'X'
VECTOR_TYPE = 'VectorXd'
MATRIX_TYPE = 'MatrixXd'
DEFAULT_ARGUMENT_ARRAY_DTYPE = VECTOR_TYPE + ' &'
DEFAULT_CLASS_NAME = 'CompilerProblem'
OUTPUT_ARRAY = 'vec_output'                 # Additional vector output
PROBABILITY_SELECT = 'probability_select'
PROBABILITY_SELECT_USED = 'probability_select_used'
COMPILER_PROBLEM_H = 'compiler_problem.h'

SOURCE_FILE_BEGIN = """
/* A problem automatically generated by our compiler infrastructure.
   Only include this header from one source file. */

#ifndef _compiler_problem_h
#define _compiler_problem_h

#include "problems.h"
"""

SIGMA_PARAM = '__sigma'

STUB_G = """
double g(const VectorXd &L, const VectorXd &%s) {
    return f(L);
}
""" % (SIGMA_PARAM)

SOURCE_FILE_END = """
#endif
"""

# Different modes for to_source()
MODE_VARNAME = 'varname'                # Generate variable name for use in expression
MODE_INLINE = 'inline'                  # Usually generate inlined expression code (do not generate temporary variable names)
MODE_ALWAYS_INLINE = 'always_inline'    # Always inline (never generate references to existing vars or empty strings)
MODE_SAMPLE_PROBLEM = 'sample_problem'  # Generate fused/inlined initialization code in sample_problem() method
MODE_SIDE_EFFECTS = 'side_effects'      # Generate ordinary statements with side effects (e.g. for loops)

# Approximation modes for each AST node (Expr instance)
APPROX_NONE     = 'none'                            # No approximation
APPROX_MC       = 'mc'                              # Monte Carlo sampled approximation *
APPROX_GAUSSIAN = 'gaussian'                        # Gaussian (first-order) approximation or other kernel if convolution diverges
APPROX_DORN     = 'dorn'                            # Dorn et al approximation *

# Special values for Expr.approx_rho (approximation rule for correlation constant rho). See class Expr for documentation.
APPROX_RHO_ZERO     = 'zero'                          # Use rho=0 (unless a symbolic step can determine rho exactly).
APPROX_RHO_GRADIENT = 'gradient'                      # Approximate rho from gradient.
APPROX_RHO_GRADIENT2= 'gradient2'                     # Approximate covariance directly from gradient
APPROX_RHO_CONSTANT = 'constant'                      # Approximate rho by sampling from the training data (just sample points from the model)

DEFAULT_APPROX_MC_SAMPLES = 16                        # Default sample count for APPROX_MC mode

# List of all approximation modes
all_approx_modes = [APPROX_NONE, APPROX_DORN, APPROX_GAUSSIAN, APPROX_MC]

# List of all approximation modes that can be used anywhere
always_valid_approx_modes = [APPROX_NONE, APPROX_DORN, APPROX_GAUSSIAN, APPROX_MC]

no_generate_duplicates = True                           # Do not generate duplicate code

# * Can transform a whole sub-graph of the AST (has non-local effects), e.g. APPROX_MC generates passes n samples through the sub-graph

do_clamp_var = False                                    # Ugly workaround for bugs due to negative variances: clamp all variances to be positive. Not recommended...instead it is recommended to make robust each function to zero (or negative) input variance.

prefer_tent_pow = False                                 # Prefer tent approximation in Heckbert's repeated integration for pow()
fract_bandlimit = 'tent'                                # One of 'box', 'tent', 'sampled'
default_nsamples = 10                                   # Default number of samples for mode 'sampled'
probabilistic_fract = True                              # Probabilistically bandlimit fract() with two modes if bimodal (only for 'box' mode)
continuous_probabilistic_fract = True
probabilistic_tent_fract = True
tune_fract = False                                      # If true, fract_bandlimit will be tuned to select from 'tent' or 'box_probabilistic'
DEFAULT_FRACT_MODE = 'probabilistic'                             # Default fract_mde
allow_different_fract = True

check_zero_variance = True                              # Check and handle cases of zero variance (or negative, due to round-off error)
check_zero_variance_mc = False                          # Whether Monte Carlo (MC, i.e. multi-sample antialiasing) should check zero/negative variance

continuous_comparisons = True
bessel_correction = False                               # Use Bessel's correction to sample variance

cores = 8                                               # Number of cores to use for make

report_memory = False                                   # For debugging, report memory usage while approximating

compile_lock = None
print_benchmark = True                                  # Print some time benchmarks

DEFAULT_APPROX = APPROX_NONE

INT_TYPE = 'int'
REAL_TYPE = 'double'
VOID_TYPE = 'void'
STR_TYPE = 'str'

C_PRIMITIVE_TYPES = [INT_TYPE, REAL_TYPE, VOID_TYPE, STR_TYPE]

DERIV_PREFIX = 'dans_d'                                 # Prefix before derivative variables

if report_memory:
    import psutil

    def memory_usage():
        return psutil.Process().memory_info().rss

class NoApprox(Exception):
    """
    The given choice of approximations is not allowed.
    """

def infinite_interval():
    try:
        return interval.interval[-interval.inf, interval.inf]
    except:
        return interval.interval[-interval.inf, interval.inf]

def is_matrix(dtype):
    return dtype == MATRIX_TYPE

def select_variance(cond, a, b):
    if check_zero_variance:
        return select(cond, a, b)
    return a

class CompilerParams:
    def __init__(self, **kw):
        self.var_list = []                  # Variables indexed by evaluation order
        self.var_type = []                  # Variable type by evaluation order.
        self.instance_dtype = {}            # Maps instance var name to dtype if instance var.
        self.name_to_order = {}             # Map variable name to evaluation order.
        
        self.root = True                    # Processing root node in expression?
        self.mode = MODE_VARNAME            # One of MODE_*.
        self.approx = DEFAULT_APPROX
        self.recurse = True                 # Whether to include child node source code when Expr.to_source() is called.
        self.cache_to_source = {}           # Maps original Expr id to source
        self.cache_expr_EV = {}             # Maps original (non-transformed) Expr id to transformed Expr expected value and variance.
        self.sigma = None                   # Stores ArgumentArray instance for sigma variable of g, g_gradient
        self.compute_g = True               # Whether to compute g and functions in to_source()
        self.verbose = DEFAULT_VERBOSE      # Verbosity level, 0=none, 1=some, 2=more.
        self.save_method = ''               # Save method declaration (if any)
        self.global_header = []             # List of strings for classes and global variables
        self.log_rho = False                # Log list of correlation coefficients rho
        self.log_rho_count = 0              # Number of correlation coefficients logged
        self.statement_ids = set()          # Ids of nodes that correspond to generated statements (to prevent duplicating statements)
        self.log_approx_rho_gradient = False        # Whether to log approx_rho_gradient expressions
        self.log_approx_rho_gradient_list = []      # List where approx_rho_gradient expressions are logged
        self.log_approx_cov_gradient = False        # Whether to log approx_cov_gradient expressions
        self.log_approx_cov_gradient_list = []      # List where approx_cov_gradient expressions are logged
        self.generated_nodes = []
        self.constructor_code = []          # List of custom code strings to go at end of constructor
        self.trace = False                  # Print values of variables using printfs
        self.samples = 1                    # Samples of f and g evaluated at compile time
        self.rng_counter = {}               # Random number generator counter
        self.channel = None                 # Channel of a parent node visited in to_expectation_variance() (if one is known).
        self.msaa_samples = 1
        
        for (key, value) in kw.items():
            if hasattr(self, key):
                setattr(self, key, value)
            else:
                raise ValueError('unknown key for CompilerParams: %s (no corresponding attribute)'%key)

    def reset_vars(self):
        self.var_list = []
        self.name_to_order = {}
    
    def reset(self):
        self.statement_ids = set()
        self.generated_nodes = []
        self.rng_counter = {}
    
    def as_reset_statements(self):
        ans = copy.copy(self)
        ans.statement_ids = set()
        return ans
    
    def __repr__(self):
        return 'CompilerParams(%s)]'%(', '.join('%s=%r'%(key, getattr(self, key)) for key in self.__dict__.keys()))
    
    def deroot(self):
        """
        A copy of self that has root set to False (not processing root node in expression).
        """
        ans = copy.copy(self)
        ans.root = False
        return ans
    
    def as_mode(self, mode):
        """
        A copy of self that has mode set to the given target.
        """
        ans = copy.copy(self)
        ans.mode = mode
        return ans
    
    def get_varname(self, short_name, full_name, dtype, is_instance=False):
        """
        Convert a variable or expression name into a variable numbered by evaluation order.
        
        Here short_name is a descriptive identifier string that will be used in the variable, and
        full_name is a full unique identifier string.
        
        Return the converted variable name.
        """
        if is_instance:
            self.instance_dtype[full_name] = dtype
            return full_name
        if full_name in self.name_to_order:
            return self.var_list[self.name_to_order[full_name]]
        n = len(self.var_list)
        self.name_to_order[full_name] = n
        allowed_chars = set(string.ascii_letters + string.digits)
        remain = '_' + ''.join([c if c in allowed_chars else '_' for c in short_name])
        if remain == '_':
            remain = ''
        converted_name = 'var%03d'%n + remain
        self.var_list.append(converted_name)
        self.var_type.append(dtype)
#        print('get_varname', converted_name)
        return converted_name
    
    def var_declarations(self, is_instance=False):
        if is_instance:
            return '\n'.join(dtype + ' ' + name + ';' for (name, dtype) in self.instance_dtype.items())
        else:
            return '\n'.join(self.var_type[i] + ' ' + self.var_list[i] + ';' for i in range(len(self.var_list)))

def sample_problem_code(e, compiler_params):
    """
    Get initializations. Here is_instance is whether variables should be class instance variables (if False, function variables).
    """
    compiler_params = copy.copy(compiler_params)
    compiler_params.mode = MODE_SAMPLE_PROBLEM
    compiler_params.root = True
    ans = '\n'.join([node.to_source(compiler_params) for node in e.all_nodes()])
    while '\n\n' in ans:
        ans = ans.replace('\n\n', '\n')
    return ans

def simplify(e):
    """
    Return a copy of the given Expr that is simplified.
    """
    e = copy.deepcopy(e)
    return e.simplify()

def eliminate_duplicates(s, verbose=False):
    #return s
    if verbose or extra_verbose:
        print('before eliminate_duplicates:')
        print(s)
    #print('-'*80)
    L = s.split('\n')
    ans = []
    ans_set = set()
    for x in L:
        xs = x.strip()
        if not '{' in xs and not '}' in xs and not xs.startswith('//'):
            if xs not in ans_set:
                ans.append(x)
                ans_set.add(xs)
        else:
            ans.append(x)
    ans_s = '\n'.join(ans)
    if verbose or extra_verbose:
        print('after eliminate_duplicates:')
        print(ans_s)
        traceback.print_stack()
    return ans_s

def reorder_fix_dependencies(s, prune_unused=True):
    """
    A hack to reorder C code so as to fix variable dependencies.
    """
    if extra_verbose:
        print_header('reorder_fix_dependencies:')
        print(s)
    L = s.split('\n')
    
    varnames = []
    line_to_varname = {}
    for (i, line) in enumerate(L):
        line = line.strip()
        if '=' in line:
            before_eq = line[:line.index('=')]
            if before_eq.endswith('+') or before_eq.endswith('-') or before_eq.endswith('*') or before_eq.endswith('/'):
                before_eq = before_eq[:-1]
            before_eq = before_eq.strip()
            before_eq_syms = before_eq.split()                          # LHS symbols
            if before_eq_syms[0] in C_PRIMITIVE_TYPES:
                before_eq_syms = before_eq_syms[1:]
            if extra_verbose:
                print(i, before_eq_syms)
            if len(before_eq_syms) == 1:
                varname = before_eq_syms[0]
                varnames.append(varname)
                line_to_varname[i] = varname
    varname_to_line = util.inverse_dict(line_to_varname)
    if extra_verbose:
        print('line_to_varname:', line_to_varname)
        print('varname_to_line:', varname_to_line)
    
    line_deps = {}                                                      # Maps line to other lines that it depends on
    for (i, line) in enumerate(L):
        if i in line_to_varname:
            after_eq = line[line.index('='):]
            
            deps = []
            for var_match in varnames:                                  # Check RHS symbols
                if var_match in after_eq:
                    deps.append(varname_to_line[var_match])

            line_deps[i] = deps

    line_inverse_deps = util.inverse_dict_multivalued(line_deps)        # Maps line to other lines that depend on it

    if extra_verbose:
        print('varnames:', varnames)
        print('line_deps:', line_deps)

    ans = []
    ans_lines = set()
    
    def visit(i):
        if i not in ans_lines:
            ans_lines.add(i)
            for j in line_deps.get(i, []):
                if j not in ans_lines:
                    visit(j)
            ans.append(L[i])
    
    for i in range(len(L)):
        skip = False
        if prune_unused:
            line_strip = L[i].lstrip()
            skip = len(line_inverse_deps.get(i, [])) == 0 and any(line_strip.startswith(primitive) for primitive in C_PRIMITIVE_TYPES)
        if not skip:
            visit(i)

    return '\n'.join(ans)

def system(cmd):
#    print(cmd)
#    return os.system(cmd)
    try:
        cmd_output = subprocess.check_output(cmd, stderr=subprocess.STDOUT, shell=True, universal_newlines=True);
    except subprocess.CalledProcessError as exc:
        print(exc.output)
        raise ValueError("Subprocess failed with code ", exc.returncode)
    else:
        return cmd_output

class ParseError(Exception):
    pass

def parse_output_float(s, field, multiple=False, allow_not_found=False):
    """
    Parse a float from the output of proj/csolver/main with the given field name.
    
    If multiple is True then return a list of floats.
    """
    ans = []
    L = s.split('\n')
    for line in L:
        line_split = line.split(':', 1)
        if line_split[0] == field:
            v = float(line_split[1].strip())
            if multiple:
                ans.append(v)
            else:
                return v
    if allow_not_found:
        return 0.0
    if not multiple:
        raise ParseError('missing field in output: %r'%field)
    return ans

def locate_orig_compiler_dir():
    """
    Locate the original compiler directory (csolver) before making copies for each process id.
    """
    return os.path.abspath('../csolver')

def locate_compiler_dir(print_command, compiled_already={}, get_orig=False):
    """
    For inter-process safety, locate a different compiler (csolver) directory for each machine and process id.
    """
    global compile_lock
    if compile_lock is None:
        compile_lock = filelock.FileLock(os.path.join(locate_orig_compiler_dir(), 'compile_lock'))
    
    our_id = util.machine_process_id()

    orig_path = locate_orig_compiler_dir()
    if get_orig:
        return orig_path

    id_path = os.path.abspath('../.csolver_build_%s' % our_id)
    if not compiled_already.get(our_id, False):
        with compile_lock:
            make(orig_path, print_command=print_command, rule='nonfinal')
            if os.path.exists(id_path):
                shutil.rmtree(id_path)
        compiled_already[our_id] = True
    
    if not os.path.exists(id_path):
        os.makedirs(id_path)
        def source_files(wildcard_L):
            return sum([glob.glob(os.path.join(orig_path, wildcard)) for wildcard in wildcard_L], [])
        for filename in source_files(['*.h', '*.cpp', '*.o', '*.d', '*.gch', 'Makefile']):
            if os.path.split(filename)[1] not in [COMPILER_PROBLEM_H, 'check_compiler.o']:
                dest_filename = os.path.join(id_path, os.path.split(filename)[1])
                shutil.copyfile(filename, dest_filename)
                shutil.copystat(filename, dest_filename)
    def remove_if_exists(path):
        if os.path.exists(path):
            shutil.rmtree(path)
    atexit.register(remove_if_exists, id_path)
    return id_path

def locate_compiler_problem(full_path=True, print_command=True, get_orig=False):
    csolver_path = locate_compiler_dir(print_command, get_orig=get_orig)
    h_filename = COMPILER_PROBLEM_H
    if full_path:
        return os.path.join(csolver_path, h_filename)
    else:
        return (csolver_path, h_filename)

class CheckFailed(Exception):
    pass

def make(csolver_path, print_command=True, rule=''):
    old_path = os.getcwd()
    os.chdir(csolver_path)
    make_command = 'make' + (' -j%d' % cores if cores > 1 else '') + (' ' + rule if rule != '' else '')
    T1 = time.time()
    try:
        system(make_command)
    except ValueError:
        raise CheckFailed
    T2 = time.time()
    if print_benchmark:
        print('Compiled C++ in %f seconds' % (T2-T1))
    os.chdir(old_path)

def check(e, compiler_params, cmd=None, time_error=False, nerror=-1, nground=-1, nsamples=0, precompute_samples=None, print_command=False, log_rho=False, do_copy=True, extra_args='', do_run=True, do_compile=True, get_command=False, skip_save=False, ndims=-1):
    """
    Convert Expr to finalized source code and (by default) run to check the correctness or performance of the output code.
    
    If time_error is True then return time and error information in a dict. Here nerror and nground control the
    number of samples to estimate the error and estimate the ground truth by convolution (if -1, use default).
    
    If log_rho is True then return log_rho as a key in a dict containing correlation coefficients.
    
    If precompute_samples is an integer then set the #define PRECOMPUTE_SAMPLES to the given integer in problems.cpp.
    
    If do_compile is True then generate and compile C++ code. If do_run is True then run the target program (unless get_command is True, in which
    case, do not run but instead return the command to run (with full path-name included)."
    """
    ans = {}

    (csolver_path, h_filename) = locate_compiler_problem(False, print_command)
    orig_h_filename = locate_compiler_problem(True, get_orig=True)
    try:
        arg_array = locate_argument_array(e)
        arg_array_ndims = arg_array.ndims
    except NoArgumentArray:
        arg_array_ndims = 1
    git_command = 'git checkout ' + h_filename
    if cmd is None:
        check_command = './main check_compiler --ndims %d --samples %d' % (ndims if ndims > 0 else arg_array_ndims, nsamples)
    else:
        check_command = cmd
    if time_error:
        check_command += ' --error %d --ground %d' % (nerror, nground)
    if log_rho:
        check_command += ' --print_rho 1'
    if len(extra_args):
        check_command += ' ' + extra_args
    if skip_save:
        check_command += ' --skip_save 1'
    if precompute_samples is not None:
        c_full_filename = os.path.join(locate_compiler_dir(print_command), 'problems.cpp')
        util.change_c_define(c_full_filename, 'PRECOMPUTE_SAMPLES', str(int(precompute_samples)))

    if do_compile:
        T0 = time.time()
        if compiler_params.verbose >= 1:
            print('in check, before to_source()')
        source = to_source(e, compiler_params, info_d=ans, do_copy=do_copy)
        if compiler_params.verbose >= 1:
            print('in check, after to_source()')
        T1 = time.time()
        h_filename_full = os.path.join(csolver_path, h_filename)
        current_source = ''
        if os.path.exists(h_filename_full):
            with open(h_filename_full, 'rt') as f:
                current_source = f.read()
        if current_source != source:
            with open(h_filename_full, 'wt') as f:
                f.write(source)
            shutil.copyfile(h_filename_full, orig_h_filename)
        if print_benchmark:
            print('Generated C++ code in %f seconds' % (T1-T0))
    
    old_path = os.getcwd()
    os.chdir(csolver_path)

    if do_compile:
        make(csolver_path, print_command)

    if print_command and do_run:
        print(check_command)

    if get_command:
        ans = os.path.join(os.getcwd(), check_command)
        do_run = False

    if do_run:
        T0 = time.time()
        check_out = subprocess.check_output(check_command, shell=True)
        T1 = time.time()
        check_out = check_out.decode('utf-8')
        if compiler_params.verbose >= 1:
            print(check_out)

    os.chdir(old_path)
    if get_command:
        return ans

    if do_run:
        if time_error:
            keys = ['time_f', 'time_g', 'error_f', 'error_g', 'time_f_geom', 'time_g_geom']
            for key in keys:
                ans[key] = parse_output_float(check_out, key)
            ans['time_g_nlm'] = parse_output_float(check_out, 'time_g_nlm', allow_not_found=True)
        if log_rho:
            if compiler_params.verbose:
                print('check(), raw output:')
                print(check_out)
            i = 0
            log_rho_L = []
            while True:
                key = 'log_rho_%d' % i
                try:
                    log_rho_L.append(parse_output_float(check_out, key))
                except ParseError:
                    break
                i += 1
            ans['log_rho'] = log_rho_L
        return ans

def print_header(s, file=None):
    if file is None:
        file = sys.stdout
    print('-'*80, file=file)
    print(s, file=file)
    print('-'*80, file=file)

def to_approx(e, compiler_params, get_expectation=True, e_base=None):
    """
    Return a copy of the input Expr graph that approximates the original Expr graph.
    
    If e_base is specified then it is searched instead to locate the unknown input array.
    """
    if compiler_params.verbose >= 1:
        print('entering to_approx')
        print('expression of to_approx:')
        pprint.pprint(e)
    e = copy.deepcopy(e)
    if compiler_params.verbose >= 1:
        print('to_approx, calc_parents()')
    e.calc_parents()
    if compiler_params.verbose >= 1:
        print('to_approx, check_consistency()')
    e.check_consistency(compiler_params, False, False)
    if compiler_params.verbose >= 1:
        print('to_approx, locate_argument_array()')
    try:
        a = locate_argument_array(e_base if e_base is not None else e)
        compiler_params.sigma = ArgumentArray(SIGMA_PARAM, bounds=(0.0, interval_range(a.interval)*MAX_SIGMA_RATIO))
    except NoArgumentArray:
        compiler_params.sigma = ArgumentArray(SIGMA_PARAM, bounds=(0.0, 1.0))
    if compiler_params.verbose >= 1:
        print('to_approx, to_expectation_variance()')
    return copy.deepcopy(e.to_expectation_variance(compiler_params)[0 if get_expectation else 1])

class NoArgumentArray(Exception):
    pass

def is_unknown_array(node):
    """
    Returns whether the given Expr is an ArgumentArray for the unknown array argument of the solver.
    """
    return isinstance(node, ArgumentArray) and node.name == DEFAULT_ARGUMENT_ARRAY_NAME

def locate_argument_array(e):
    """
    Return ArgumentArray instance for unknown array given objective function Expr, or raise exception if not found.
    """
    for node in e.all_nodes():
        if is_unknown_array(node):
            return node
    raise NoArgumentArray

def to_source_nonfinal(e, compiler_params, eliminate=True, is_f=False):
    """
    Convert Expr to non-finalized source code (no wrapping class).
    """
    s = e.to_source(compiler_params)
    if compiler_params.verbose >= 1:
        print_header('to_source_nonfinal result before eliminate_duplicates:')
    if eliminate:
        s = eliminate_duplicates(s)
    if compiler_params.verbose >= 1:
        print_header('to_source_nonfinal result after eliminate_duplicates:')
    if compiler_params.verbose >= 1:
        print_header('to_source_nonfinal after adding logging code:')
        print(s)
    return s

def repeated_simplify_inplace(e, max_simplifications=5, verbose=False):
    max_simplifications = 5
    n_simplify = 0
    e_current = ''
    while n_simplify < max_simplifications:
        e_before = e_current
        e = e.simplify()
        n_simplify += 1
        e_current = e.unique_str()
        if e_current == e_before:
            break
    if verbose:
        print('%d simplifications' % n_simplify)
    #print_header('After simplification:')
    #pprint.pprint(e)
    return e

def to_source(e, compiler_params, g_only=False, info_d=None, do_copy=True):
    """
    Convert Expr to finalized source code, including variable and function declarations.
    """
    e = remove_redundant_exprs(e) #copy.deepcopy(e)
#    e = remove_redundant_exprs(e) #copy.deepcopy(e)
    #print('simplifying %d nodes' % len(e.all_nodes()))

    if extra_verbose:
        print_header('to_source input program before simplify:')
        pprint.pprint(e)
    e = repeated_simplify_inplace(e)
    e.calc_parents()
    if extra_verbose:
        print_header('to_source input program:')
        pprint.pprint(e)
    rng_counter = compiler_params.rng_counter
    if do_copy:
        c0 = compiler_params
        compiler_params = copy.deepcopy(compiler_params)
        compiler_params.constructor_code = c0.constructor_code
    compiler_params.root = True
    compiler_params.mode = MODE_SIDE_EFFECTS
    compiler_params.reset()

    if g_only:
        compiler_params.reset_vars()

    if compiler_params.verbose:
        print('g_only:', g_only)
    
    f = to_source_nonfinal(e, compiler_params, is_f=not g_only)
    if compiler_params.trace:
        f += '\nprintf("\\n");\n'

    max_counter = builtin_max(rng_counter.values()) if len(rng_counter) else 0
    if max_counter != 0:
        f += '\n' + 'Gaussian_RNG::advance(%d);'%max_counter

    f_return = '\n' + 'return ' + e.to_source(compiler_params.as_mode(MODE_VARNAME)) + ';'
    unknown_array = 'const ' + DEFAULT_ARGUMENT_ARRAY_DTYPE + ' ' + DEFAULT_ARGUMENT_ARRAY_NAME
    sigma_array = 'const ' + DEFAULT_ARGUMENT_ARRAY_DTYPE + ' ' + SIGMA_PARAM
    f_declare = REAL_TYPE + ' f(' + unknown_array + ')'
    if g_only:
        f_declare = REAL_TYPE + ' g(' + unknown_array + ', ' + sigma_array + ')'
        
        prob_vars = [var_name for var_name in compiler_params.var_list if PROBABILITY_SELECT in var_name]
        if len(prob_vars):
            f += '\n' + PROBABILITY_SELECT_USED + ' = ' + '||'.join(prob_vars) + ';\n'

    f = f_declare + ' {\n' + indent(f + f_return) + '\n}'
    if info_d is not None:
        info_d['g_lines' if g_only else 'f_lines'] = f.count('\n')
    
#    d = dependencies(e, compiler_params)
#    print('Dependencies:')
#    pprint.pprint(d)
#    print('-'*80)

    try:
        arg_array = locate_argument_array(e)
        init_bounds_lo = '\n'.join('    bound_lo[%d] = %f;' % (i, arg_array.bound_list[i][0]) for i in range(arg_array.ndims))
        init_bounds_hi = '\n'.join('    bound_hi[%d] = %f;' % (i, arg_array.bound_list[i][1]) for i in range(arg_array.ndims))
    except NoArgumentArray:
        init_bounds_lo = init_bounds_hi = ''

    if g_only:
        return f + '\n'

    class_declares = compiler_params.var_declarations(True)
    if compiler_params.verbose >= 1:
        print('before sample_init eliminate_duplicates')
    sample_init = eliminate_duplicates(sample_problem_code(e, compiler_params))
    if compiler_params.verbose >= 1:
        print('after sample_init eliminate_duplicates')
    sample_problem = 'void sample_problem() {\n' + indent(sample_init) + '\n}\n'

    g_source = STUB_G
    if compiler_params.compute_g:
        if compiler_params.verbose >= 1:
            print('to_source(), computing g, calling to_approx')
        cp = copy.copy(compiler_params)
        cp.compute_g = False
        g_expr = to_approx(e, cp)

        if compiler_params.verbose >= 1:
            print_header('Approximated:')
            pprint.pprint(g_expr)

        g_source = to_source(g_expr, cp, True, info_d, do_copy=do_copy)
        
        if compiler_params.verbose >= 1:
            print_header('g_source:')
            print(g_source)
#        print('Done with g')

    if compiler_params.verbose >= 1:
        print('to_source(), compiling final string')

    ctor = DEFAULT_CLASS_NAME + """(int ndims_) {
    ndims = ndims_;
    bound_lo = VectorXd::Constant(ndims, 0.0);
    bound_hi = VectorXd::Constant(ndims, 1.0);
%s
%s
    log_rho_reserve(%d);
    sample_problem();
%s
}
    """ % (init_bounds_lo, init_bounds_hi, compiler_params.log_rho_count, indent('\n'.join(compiler_params.constructor_code)))

    c = 'class ' + DEFAULT_CLASS_NAME + ': public ProblemLogRho { public:\n' + indent(class_declares) + '\n\n' + indent(sample_problem) + '\n' + indent(ctor) + '\n' + indent(f) + '\n\n' + indent(g_source) + '\n' + indent(compiler_params.save_method) + '\n};'
    c = SOURCE_FILE_BEGIN + '\n' + '\n'.join(compiler_params.global_header) + '\n' + c + '\n' + SOURCE_FILE_END

    return c

def to_expr(const_or_expr):
    """
    Convert constant or expression typically to Expr type but with special cases for handling None or ConstExpr.
    """
    if isinstance(const_or_expr, int_types + float_types + (str,)):
        return ConstExpr(const_or_expr)
    elif isinstance(const_or_expr, type(None)):
        return None
    elif isinstance(const_or_expr, Expr):
        return const_or_expr
    elif isinstance(const_or_expr, tuple):
        return Tuple(const_or_expr)

    raise ValueError('unknown case: ', const_or_expr)

def indent(s, count=4):
    lines = s.split('\n')
    return '\n'.join(' '*count + line for line in lines)

def remove_redundant_exprs(e, verbose=False):
    """
    Return copy of Expr graph with redundant Exprs consolidated into a single instance.
    """
    if verbose:
        print('='*80)
        print('enter remove_redundant_exprs')
        e0 = copy.deepcopy(e)
    e = copy.deepcopy(e)
    repr_to_expr = {}
    
    repr_cache = {}

    all_nodes = e.all_nodes_dfs()
    if verbose:
        print('remove_redundant_exprs, %d nodes' % len(all_nodes))
    for (j, node) in enumerate(all_nodes):
        if verbose:
            print('remove_redundant_exprs, node %d/%d' % (j, len(all_nodes)))
        #print(j, len(all_nodes), len(node.children))
        for (i, child) in enumerate(node.children):
            if isinstance(child, Expr):
                #e.calc_parents()
                r = child.repr(False, repr_cache)
                seen = r in repr_to_expr
                if verbose:
                    print('-'*80)
                    print('seen:', seen)
                    print('node repr:', r)
                    print('node full repr:', child.repr(True))
                    print(' => ', id(repr_to_expr[r]) if seen else '(no remapping)')
                    print('-'*80)
                if seen:
                    node.children[i] = repr_to_expr[r]
                if not seen:
                    repr_to_expr[r] = child
    e.calc_parents()

    if verbose and e.repr(False) != e0.repr(False):
        print_header('input Expr for remove_redundant_exprs:')
        pprint.pprint(e0)
        print_header('result Expr for remove_redundant_exprs:')
        pprint.pprint(e)
        
    if verbose:
        print('='*80)

    return e

def gradient(compiler_params, e, vars, simplify=True, verbose=False, allow_none=False):
    """
    Take gradient of Expr e with respect to given variables (a list of Expr), using reverse mode automatic differentiation.
    
    Here vars must be sub-nodes of e. Returns the gradient as a list of Expr.
    
    The returned gradient shares nodes with the expression e. The parents of the expression e may be modified.
    """
    if verbose:
        print('*'*80)
        print('gradient')
        print('*'*80)
        print('input:')
        pprint.pprint(e)
        print('*'*80)
    id_to_deriv = {}                # Maps node Expr id to de_dnode (derivative of e with respect to derivative of node).
    e.calc_parents()
    
    ans = [None] * len(vars)
    
    def allow_visit(parent, child):
        return not child.has_param_parents()

    all_nodes = e.all_nodes_dfs(allow_visit)
    
    if compiler_params.verbose:
        print('all_nodes (bottom up):', [id(x) for x in all_nodes])
    all_nodes = all_nodes[::-1]
    if compiler_params.verbose:
        print('all_nodes (final):', [id(x) for x in all_nodes])
    
    for node in all_nodes:
        if verbose:
            print('='*80)
            print('gradient, node:', id(node))
            print(node.repr())
            print('='*80)
        if node is e:
            de_dnode = ConstExpr(1.0)
        else:
            de_dnode = None

            parent_count = {}
            for parent in node.parents:
                parent_id = id(parent)
                if verbose:
                    print('-'*80)
                    print('  parent:', parent_id)
                    print(parent.repr())
                    print('-'*80)
                if parent_id not in parent_count:
                    parent_count[parent_id] = 0
                else:
                    parent_count[parent_id] += 1

                g_parent = parent.gradient(compiler_params)

                child_indices = util.get_indices([id(x) for x in parent.children if isinstance(x, Expr) and x.differentiate_wrt()], id(node))
                if len(child_indices) == 0:
                    continue
                sel_child = parent_count[parent_id]
                if verbose:
                    print('child_indices:', child_indices)
                    print('sel_child:', sel_child)
                child_index = child_indices[sel_child]
                
                assert 0 <= child_index < len(g_parent)
                
                g = g_parent[child_index]

                dterm = g * id_to_deriv[id(parent)]
            
                if de_dnode is None:
                    de_dnode = dterm
                else:
                    de_dnode = de_dnode + dterm
                
                if verbose:
                    print('  dterm:')
                    pprint.pprint(dterm)
                    print('  de_dnode:')
                    pprint.pprint(de_dnode)

            if de_dnode is None:
                de_dnode = ConstExpr(1.0)

        id_to_deriv[id(node)] = de_dnode
        
        node_repr = node.unique_str()
        for (i, var) in enumerate(vars):
            var_repr = var.unique_str()
            if var_repr == node_repr:
                if ans[i] is None:
                    ans[i] = de_dnode
                else:
                    ans[i] = ans[i] + de_dnode

    for i in range(len(ans)):
        if ans[i] is None and allow_none:
            ans[i] = ConstExpr(0.0)
            continue
        if simplify:
            ans[i] = ans[i].simplify()
        if ans[i] is None:
            assert False, 'variable not present in expression e:\nindex %d => variable:\n%r\ngradient expr:\n%r' % (i, vars[i], e)
    return ans

def identical(a, b):
    """
    Check whether either Expr or list of Exprs a and b are identical (cast elements to Expr using to_expr() if needed).
    """
    if isinstance(a, Expr):
        return a.identical(b)
    elif isinstance(a, (list, tuple)):
        if len(a) != len(b):
            return False
        for i in range(len(a)):
            av = a[i]
            bv = b[i]
            if not isinstance(av, Expr):
                av = to_expr(av)
            if not isinstance(bv, Expr):
                bv = to_expr(bv)
            if not av.identical(bv):
                return False
        return True

def intersect_exprs(La, Lb):
    """
    Intersect two lists of Exprs.
    """
    b_unique_strs = set([node.unique_str() for node in Lb])
    return [node for node in La if node.unique_str() in b_unique_strs]

def union_exprs(La, Lb):
    """
    Union two lists of Exprs.
    """
    b_strs = set([node.unique_str() for node in Lb])
    a_extra_nodes = [node for node in La if node.unique_str() not in b_strs]
    return a_extra_nodes + Lb

def exclude_exprs(La, Lb):
    """
    Returns list that's in a, but not in b
    """
    b_unique_strs = set([node.unique_str() for node in Lb])
    return [node for node in La if node.unique_str() not in b_unique_strs]

def infix_repr(e):
    """
    Convert Expr or list of Expr to human-readable, infix, C-like code str.
    """
    if isinstance(e, (tuple, list)):
        return '[' + ', '.join(infix_repr(x) for x in e) + ']'
    c = CompilerParams()
    c.mode = MODE_ALWAYS_INLINE
    return e.to_source(c)

def linenos_from_frame(current_frame, depth=10):
    ans = []
    ans.append(current_frame.f_lineno)
    for i in range(depth):
        current_frame = current_frame.f_back
        if current_frame is None:
            break
        ans.append(current_frame.f_lineno)
    return ans

def running_sum(a, b):
    """
    Add Expr a and b, unless either is None, in which case, return the other (None is treated as 0).
    """
    if a is None:
        return b
    elif b is None:
        return a
    return a + b

class Expr:
    """
    Expression type.
    
    Attributes:
    children --- A list of children for the expression (of any type, but AST nodes are of type Expr).
    dtype --- Type of expression, one of INT_TYPE or REAL_TYPE ('double').
    approx --- Approximation mode for this node, one of APPROX_*.
    approx_rho --- For APPROX_GAUSSIAN mode, a pair of integers (k, m) that control estimation of the correlation coefficient rho,
                   where k is samples per function eval, m is evals to average over. Special values are APPROX_RHO_ZERO (no rho),
                   APPROX_RHO_GRADIENT (approximate using gradient), APPROX_RHO_CONSTANT (approximate as a constant by sampling
                   from the training data).
    approx_rho_const --- Constant for correlation coefficient. If approx_rho is APPROX_RHO_CONSTANT, this is the float constant used.
                         Can be computed for all nodes of an Expr graph which allow a rho parameter by calling calc_approx_rho_constant().
    approx_mc_samples ---- Sample count for APPROX_MC mode.
    interval -- An interval.interval instance for the known range of the current node.
                Inferred by interval arithmetic, or can be set explicitly with bound().
    """
    def __init__(self, frame_depth=2):
        self.children = []
        self.approx = APPROX_NONE
        self.approx_rho = APPROX_RHO_ZERO
        self.approx_rho_const = None
        self.approx_rho_index = -1
        self.approx_mc_samples = DEFAULT_APPROX_MC_SAMPLES
        self.interval = infinite_interval()
        self.recurse_to_source_indices = None
        current_frame = inspect.currentframe()
        self.frame_lineno = linenos_from_frame(current_frame)
        self.channel = None
        self.approx_fract_mode = DEFAULT_FRACT_MODE
    
    def get_approx_info(self, simplify=False):
        ans = {'approx': self.approx}
        if self.allows_approx_rho():
            ans['rho'] = self.approx_rho
            if simplify and ans['rho'] == APPROX_RHO_ZERO:
                del ans['rho']
        if self.approx == APPROX_MC:
            ans['samples'] = self.approx_mc_samples
        if self.approx in [APPROX_GAUSSIAN, APPROX_DORN]:
            if isinstance(self, Call) and self.name == 'fract':
                approx_mode = getattr(self, 'approx_fract_mode', DEFAULT_FRACT_MODE)
                ans['fract_mode'] = approx_mode
        if simplify and len(ans) == 1:
            return ans['approx']
        return ans
    
    def set_approx_info(self, d):
        if isinstance(d, str):
            self.approx = d
        else:
            self.approx = d['approx']
            self.approx_rho = d.get('rho', APPROX_RHO_ZERO)
            self.approx_mc_samples = d.get('samples', DEFAULT_APPROX_MC_SAMPLES)
            self.approx_fract_mode = d.get('fract_mode', DEFAULT_FRACT_MODE)
    
    def set_approx_mc_samples_recurse(self, v):
        for node in self.all_nodes():
            if node.approx == APPROX_MC:
                node.approx_mc_samples = v
                
    def set_approx_fract_mode_recurse(self, v):
        for node in self.all_nodes():
            if node.approx in [APPROX_GAUSSIAN, APPROX_DORN]:
                node.approx_fract_mode = v
    
    def set_approx_info_list(self, L):
        nodes = self.all_approx_nodes()
        assert len(L) == len(nodes), (len(L), len(nodes))
        for i in range(len(L)):
            nodes[i].set_approx_info(L[i])

    def __copy__(self):
        """
        Create a shallow copy which does not share the children list.
        """
        cls = self.__class__
        ans = cls.__new__(cls)
        ans.__dict__.update(self.__dict__)
        ans.children = list(ans.children)
        return ans
    
    def rho_nodes(self):
        """
        List of all nodes with node.allows_approx_rho().
        """
        return [node for node in self.all_nodes() if node.allows_approx_rho()]
    
    def subs(self, source, dest, copy=True, verbose=False):
        """
        Return a deep copy of self (unless copy is False) that has source (Expr) replaced with dest (Expr), recursively.
        """
        if copy:
            self = copy.deepcopy(self)
        source_str = source.unique_str()
        self.calc_parents()
        nsubs = 0
        for node in self.all_nodes():
            node_id = id(node)
            node_str = node.unique_str()
            parents = node.parents
            if node_str == source_str:
                for parent in parents:
                    for i in range(len(parent.children)):
                        if id(parent.children[i]) == node_id:
                            parent.children[i] = dest
                            nsubs += 1
        if verbose:
            print('subs %r => %r: %d substitutions' % (source, dest, nsubs))
        return self

    def calc_approx_rho_constant(self, compiler_params):
        """
        Compute approx_rho_constant for all nodes which allow a rho parameter.
        """
        rho_nodes = self.rho_nodes()
        
        for (i, node) in enumerate(rho_nodes):
            node.approx_rho_index = i
        cp = copy.deepcopy(compiler_params)
        cp.compute_g = False
        cp.log_rho = True
        cp.log_rho_count = len(rho_nodes)
        
        info_d = check(self, cp, log_rho=True)
        rho_L = info_d['log_rho']
        assert len(rho_L) == len(rho_nodes), (len(rho_L), len(rho_nodes))
        
        for (i, node) in enumerate(rho_nodes):
            node.approx_rho_const = rho_L[i]

    def set_approx_rho_recurse(self, v):
        """
        Set the approx_rho field to v for all nodes for which this is valid.
        """
        for node in self.rho_nodes():
            print('Setting approx_rho to %s for %r' % (v, node))
            node.approx_rho = v
    
    def list_approx_rho_constant(self):
        """
        Get list of all approx_rho_constant from nodes that allow this.
        """
        return [node.approx_rho_const for node in self.all_nodes() if node.allows_approx_rho()]
    
    def differentiate_wrt(self):
        """
        True iff self is a variable that can be differentiated with respect to.
        """
        return True
    
    def allows_approx(self):
        """
        Whether the current node has an approx field that can be set (if not, approx field should be set to APPROX_NONE).
        
        Can be overridden in subclasses, but should check whether the base class method is True before returning True.
        """
        return not self.is_unknown_getitem()
    
    def allows_approx_rho(self):
        """
        Whether current node has approx_rho property (if not, approx_rho field should be set to APPROX_RHO_ZERO).
        """
        return False
    
    def count_allows_approx(self):
        """
        Return the number of nodes that allow approximation at or under the current node.
        """
        return sum([node.allows_approx() for node in self.all_nodes()])
    
    def contains_unknown_array(self):
        """
        Whether any sub-node (including the current node) is an input unknown array.
        """
        return any([is_unknown_array(node) for node in self.all_nodes()])
    
    def bound(self, lo, hi):
        self.interval = interval.interval[lo, hi]
    
    def unique_str(self):
        ans = self.repr(False)
        return ans
    
    def identical(self, b):
        """
        Returns bool for whether self and b are identical expressions without attempting any simplification.
        """
        return self.unique_str() == b.unique_str()

    def simplify(self, seen=None):
        """
        Simplifies the given Expr in place (recursively), returning the simplified Expr.
        """
        if seen is None:
            seen = set()
        id_self = id(self)
        if id_self in seen:
            return self
        seen.add(id_self)
        self.simplify_children(seen)
        return self.simplify_impl()
    
    def simplify_impl(self):
        """
        Simplifies the given Expr but not its children in place, returning the simplified Expr.
        """
        return self
    
    def simplify_children(self, seen):
        """
        Simplifies the children of the given Expr in place.
        """
        for (i, child) in enumerate(self.children):
            if hasattr(child, 'simplify'):
                if id(child) not in seen:
                    cp = child.simplify(seen)
                    if not isinstance(cp, Expr) and cp is not None:
                        raise ValueError('Bad type for simplified expression', (cp, type(cp), child))
                    self.children[i] = cp

    def to_expectation_variance(self, compiler_params):
        """
        Return tuple of Exprs that are the (expected value, variance) of the smoothed formulation.
        
        If this method is called multiple times, it caches the result so it is unique.
        Subclasses should implement to_expectation_variance_X() which does not do the caching, where
        X is the approximation mode (or to_expectation_variance_impl, if all approximation modes are to be handled by a single method).
        """
        if self.channel is not None:
            compiler_params.channel = self.channel
        if compiler_params.verbose >= 1 and extra_verbose:
            print('to_expectation_variance, node=', str(self))
            traceback.print_stack()
        if report_memory:
            print('to_expectation_variance (memory usage: %f GB):'%(memory_usage()/1e9))

        key = self.repr(False)
        if compiler_params.verbose >= 1 and extra_verbose:
            print('to_expectation_variance, got key=', key)
        if key in compiler_params.cache_expr_EV:
            if compiler_params.verbose >= 1 and extra_verbose:
                print('to_expectation_variance, key in cache, returning cache entry:')
            ans = compiler_params.cache_expr_EV[key]
            if compiler_params.verbose >= 1 and extra_verbose:
                pprint.pprint(ans)
            return ans
        if compiler_params.verbose >= 1 and extra_verbose:
            print('to_expectation_variance, calling to_expectation_variance_impl')
        ans = self.to_expectation_variance_impl(compiler_params)
        if compiler_params.verbose >= 1 and extra_verbose:
            print('to_expectation_variance, got result of to_expectation_variance_impl')
        if do_clamp_var:
            ans = (ans[0], clamp_var(ans[1]))

        compiler_params.cache_expr_EV[key] = ans
        return ans

    def to_expectation_variance_impl(self, compiler_params):
        approx_method = 'to_expectation_variance_' + self.approx
        if compiler_params.verbose >= 1 and extra_verbose:
            print('to_expectation_variance_impl, looking up ', approx_method)
        try:
            f = getattr(self, approx_method)
        except AttributeError:
            raise AttributeError('class ' + repr(self.__class__) + ', object: %r' % repr(self) + 'has no method %s' % approx_method)
        if compiler_params.verbose >= 1 and extra_verbose:
            print('to_expectation_variance_impl, calling ', approx_method)
        ans = f(compiler_params)
        
        (E_lower, E_upper) = interval_bounds(ans[0].interval)
        
        # Clip variance interval using 0 as lower bound, and an upper bound from Popoviciu's inequality on variance
        if compiler_params.verbose >= 1 and extra_verbose:
            print('to_expectation_variance_impl, repairing returned interval')
        diff = (E_upper - E_lower)
        ans[1].interval = ans[1].interval & interval.interval[0, 0.25 * diff * diff]
        
        if compiler_params.verbose >= 1 and extra_verbose:
            print('to_expectation_variance_impl, returning')
        return ans

    def to_expectation_variance_const(self):
        return (self, ConstExpr(0.0))
    
    def to_expectation_variance_none(self, compiler_params):
        """
        Returns non-cached expected value in no approximation mode: see to_expectation().
        
        Note that nodes under the current node could still be approximated, so we use gaussian mode if available at the current
        node to combine nodes below (but with zero variance).
        """
        ans = copy.copy(self)
        if compiler_params.verbose >= 1 and extra_verbose:
            print_header('to_expectation_variance_none, node before:')
            pprint.pprint(ans)
        for i in range(len(ans.children)):
            if isinstance(ans.children[i], Expr):
                res = ans.children[i].to_expectation_variance(compiler_params)[0]
                ans.children[i] = res
        if compiler_params.verbose >= 1 and extra_verbose:
            print_header('to_expectation_variance_none, node after:')
            pprint.pprint(ans)
        return (ans, self.dorn_variance(compiler_params))

    def dorn_variance(self, compiler_params):
        V = None
        
        stddev_list = []
        var_list = []
        for child in self.children:
            if isinstance(child, Expr):
                var_current = child.to_expectation_variance(compiler_params)[1]
                var_list.append(var_current)
                if isinstance(var_current, BinaryOp) and var_current.is_power(compiler_params, 2.0):
                    stddev = var_current.a
                else:
                    stddev = var_current**0.5
                stddev_list.append(stddev)
    
        if isinstance(self, BinaryOp):
            # Compute standard deviation, which we call 'V', because we later convert it to a variance
            if self.op in ['-', '+']:
                V = sum(stddev_list)
            elif self.op == '*':
                if self.a.is_constant():
                    V = self.a * stddev_list[1]
                elif self.b.is_constant():
                    V = self.b * stddev_list[0]
                else:
                    V = stddev_list[0] * stddev_list[1]
            elif self.op == '/':
                if self.b.is_constant():
                    V = stddev_list[0] / self.b
                else:
                    V0 = stddev_list[0] / stddev_list[1]
                    V = select_nosmooth(stddev_list[1] == 0, stddev_list[0], V0)
            if V is not None:
                V = V ** 2    # Following Dorn et al. 2015, convert from sample spacing (stddev) to variance
            
        if V is None:
            if len(stddev_list) > 1:
                V = (sum(stddev_list) / len(stddev_list))**2
            elif len(stddev_list) == 1:
                V = var_list[0]
            else:
                V = ConstExpr(0.0)

        return V
        
    def to_expectation_variance_dorn(self, compiler_params):
        (E, V_ignore) = self.to_expectation_variance_gaussian(compiler_params)
        if isinstance(self, BinaryOp) and self.op not in ['<=', '<', '==', '!=', '>', '>=']:
            (E, V_ignore) = self.to_expectation_variance_none(compiler_params)
        return (E, self.dorn_variance(compiler_params))

    def is_unknown_getitem(self):
        return isinstance(self, GetItem) and is_unknown_array(self.array)
        
    def get_subgroup(self, compiler_params):
        self.calc_parents()
        if compiler_params.verbose >= 2:
            print('get_subgroup, node:')
            pprint.pprint(self)
        base_approx = self.approx
        base_samples = self.approx_mc_samples
        def allow_visit(parent, child):
            while isinstance(child, Var):
                child = child.initial_value
            if child.is_constant():
                return True
            ok = base_approx == child.approx and not is_unknown_array(child) and not child.is_unknown_getitem()
            if base_approx == APPROX_MC and child.approx_mc_samples != base_samples:
                ok = False
            return ok
        
        group = self.all_nodes(allow_visit)
        group_ids = set([id(x) for x in group])
        if compiler_params.verbose >= 2:
            print('Group:', group)
        all_nodes_minus_group = [node for node in self.all_nodes() if id(node) not in group_ids]
        if compiler_params.verbose >= 2:
            print('All nodes minus group:')
            for node in all_nodes_minus_group:
                print('node.approx=', node.approx)
                print('is_unknown_array:', is_unknown_array(node))
                print('is_unknown_getitem:', node.is_unknown_getitem())
                print('node.allows_approx:', node.allows_approx())
                print('node:')
                pprint.pprint(node)
                print('')
        group_inputs = []
        
        for node in self.all_nodes():
            if any([id(p) in group_ids for p in node.parents]) and id(node) not in group_ids:
                if compiler_params.verbose >= 2:
                    print('All nodes minus group, plus parent is in group:')
                    pprint.pprint(node)
                if not any(g.identical(node) for g in group_inputs):
                    group_inputs.append(node)
        n = len(group_inputs)
        if compiler_params.verbose >= 2:
            print('Group inputs:', group_inputs)
            print('Dimensionality:', n)

        return (group, group_ids, group_inputs, n)
        
    def check_consistency_recurse(self, compiler_params):
        """
        This method is called recursively on each node when checking consistency. Subclasses can override for custom checks.
        """
        return

    def to_expectation_variance_mc(self, compiler_params):
        """
        Returns expected value and variance for Monte Carlo approximation.
        """
        (group, group_ids, group_inputs, n) = self.get_subgroup(compiler_params)
        rewrite_inputs = [Var('in%d'%i, is_argument=True) for i in range(n)]
        
        if compiler_params.verbose >= 2:
            print('rewrite_inputs:', rewrite_inputs)
            print('print stack:')
            traceback.print_stack(file=sys.stdout)
        
        rewrite_subtree = copy.deepcopy(group[0])
        
        rewrite_index_set = set()
        for node in rewrite_subtree.all_nodes():
            for (i, child) in enumerate(node.children):
                if isinstance(child, Expr):
                    if compiler_params.verbose >= 2:
                        print('matching child node:')
                        print(child.unique_str())
                    compareL = [child.identical(g) for g in group_inputs]
                    if any(compareL):
                        rewrite_index = compareL.index(True)
                        rewrite_index_set.add(rewrite_index)
                        if compiler_params.verbose >= 2:
                            print('matched input:')
                            pprint.pprint(node.children[i])
                        node.children[i] = rewrite_inputs[rewrite_index]
        
        count = len(rewrite_index_set)
        if compiler_params.verbose >= 2:
            print('rewrite_index_set:', rewrite_index_set)
            print('count of rewritten inputs:', count)
        if count != n:
            if debug_prints:
                print('group:', group)
                print('group_ids:', group_ids)
                print('group_inputs:')
                for g in group_inputs:
                    print(g.unique_str())
                print('n:', n)
                print('rewrite_index_set:', rewrite_index_set)
                print('count of rewritten inputs:', count)
            assert count == n, (count, n)
        
        if compiler_params.verbose >= 2:
            print_header('Rewritten subtree')
            pprint.pprint(rewrite_subtree)
        
        if compiler_params.verbose >= 2:
            print_header('Source:')

        cp = compiler_params.as_reset_statements()
        func_s = to_source_nonfinal(rewrite_subtree, cp)
        idx = hashlib.md5(group[0].unique_str().encode('utf-8')).hexdigest()[:10]
        clsname = 'CompilerProblemSubfunc' + idx
        instance_name = 'subfunc_' + idx
        arg_str = ', '.join([x.arg_declare(cp) for x in rewrite_inputs])
        return_s = rewrite_subtree.to_source(cp.as_mode(MODE_VARNAME))
        instance_name2 = 'subfunc2_' + idx
        func_s = indent(indent(func_s))

        # Create expected value (E) and variance (var) of self

        E_interval = group[0].interval
        
        sampled_inputs = list(group_inputs)

        sampled_inputs_EV = [node.to_expectation_variance(compiler_params) for node in sampled_inputs]
        sampled_inputs = [node[0] for node in sampled_inputs_EV] + [node[1] for node in sampled_inputs_EV]
        
        samples = self.approx_mc_samples
        
        E = None
        var = None
        channel = self.channel
        if channel is None:
            channel = compiler_params.channel

        if compiler_params.verbose >= 2:
            print('channel:', repr(channel))

        for isample in range(samples):
            sample = []
            for j in range(n):
                if check_zero_variance_mc:
                    sigma = select_variance(sampled_inputs_EV[j][1] >= 0.0, sampled_inputs_EV[j][1]**0.5, 0.0)
                else:
                    sigma = sampled_inputs_EV[j][1]**0.5
                compiler_params.rng_counter.setdefault(channel, 0)
                sample.append(sampled_inputs_EV[j][0]+gaussian_random(compiler_params.rng_counter[channel])*sigma)
                compiler_params.rng_counter[channel] += 1
            
            rewrite_subtree_i = copy.deepcopy(rewrite_subtree)
            for j in range(n):
                if compiler_params.verbose >= 2:
                    print('subs j: %d' % j)
                rewrite_subtree_i = rewrite_subtree_i.subs(rewrite_inputs[j], sample[j], copy=False)
            var_term = rewrite_subtree_i**2
            if bessel_correction:
                var_term = var_term * ((samples)/(samples-1.0))
            E = running_sum(E, rewrite_subtree_i)
            var = running_sum(var, var_term)
            
        E = E / samples
        var = var / samples - E**2      # Uncorrected sample standard deviation
        
        if compiler_params.verbose >= 2:
            print_header('E:')
            pprint.pprint(E)
            print_header('var:')
            pprint.pprint(var)
        
        return (E, var)

    def clear_parents(self):
        for node in self.all_nodes():
            if hasattr(node, 'parents'):
                del node.parents

    def calc_parents(self):
        for node in self.all_nodes():
            node.parents = []
        for node in self.all_nodes():
            for child in node.children:
                if isinstance(child, Expr):
                    child.parents.append(node)

    def is_constant(self):
        """
        Is this a constant expression? (ConstExpr or a tree containing operators, calls, and constants)
        """
        return all(isinstance(node, (ConstExpr, BinaryOp, UnaryOp, Call)) for node in self.all_nodes())
    
    def check_acyclic(self, allow_visit=None):
        """
        Raise an exception if there is a cycle in the Expr graph. Otherwise, return self.
        """
        seen = set()
        ans = []
        def visit(node, parents):
            if id(node) in parents:
                raise ValueError('cycle detected')
            if id(node) in seen:
                return
            seen.add(id(node))
            parents = parents | set([id(node)])
            for child in node.children:
                if isinstance(child, Expr):
                    if (allow_visit is None or allow_visit(node, child)):
                        visit(child, parents)
            ans.append(node)
        visit(self, set())
        return self
    
    def all_nodes_generator(self):
        """
        A generator yielding all nodes in depth-first order.
        """
        seen = set()
        next = [self]
        while len(next):
            current = next.pop()
            id_current = id(current)
            if not id_current in seen:
                seen.add(id_current)
                if isinstance(current, Expr):
                    yield current
                    next.extend(current.children)

    def all_nodes_dfs(self, allow_visit=None, order='dfs'):
        """
        Recursive nodes including self (Expr subclasses only), in depth-first order, bottom up.
        
        This order implies that Exprs are visited in dependency order, so an Expr is visited before any parent that depends on it.
        """
        if order == 'dfs':
            order_normal = True
        elif order == 'dfs_random':
            order_normal = False
        else:
            raise ValueError('unknown order %r' % order)
        seen = set()
        ans = []
        def visit(node):
            if id(node) in seen:
                return
            seen.add(id(node))
            for child in (node.children if order_normal else util.shuffled(node.children)):
                if isinstance(child, Expr):
                    if (allow_visit is None or allow_visit(node, child)):
                        visit(child)
            ans.append(node)
        visit(self)
        return ans

    def all_nodes_order(self, order):
        if order in ['dfs', 'dfs_random']:
            return self.all_nodes_dfs(order=order)
        elif order == 'bfs':
            return self.all_nodes()
        else:
            raise ValueError('unknown order')

    def all_nodes(self, allow_visit=None):
        """
        Recursive nodes including self (Expr subclasses only), in breadth-first order, top down.
        
        If allow_visit is not None then allow_visit(parent, child) should give a bool for whether to visit the given child.
        """
        ans = [self]
        seen = set([id(self)])
        def visit(node):
            visit_next = []
            for child in node.children:
                if isinstance(child, Expr):
                    if id(child) not in seen and (allow_visit is None or allow_visit(node, child)):
                        ans.append(child)
                        seen.add(id(child))
                        visit_next.append(child)
            for child in visit_next:
                visit(child)
        visit(self)
        return ans

    @staticmethod
    def none_consistency_issue(child, parent):
        return hasattr(child, 'approx') and child.approx == APPROX_NONE and parent.approx != APPROX_NONE and child.allows_approx()
    
    def check_consistency(self, compiler_params, check_to_approx=False, check_recurse=True):
        """
        Check consistency of approximation rules recursively. Raise ValueError if not consistent.
        
        There are two different methods for checking (check_to_approx, and check_recurse), which should both give
        equivalent results (the equivalence of the two methods is checked if more_checks is enabled in the tuner).
        """
        self.calc_parents()
        for parent in self.all_nodes():
            if not parent.allows_approx():
                assert parent.approx == APPROX_NONE
            if check_recurse:
                parent.check_consistency_recurse(compiler_params)

        if check_to_approx:
            to_approx(self, compiler_params)

    def repair_consistency(self, compiler_params, more_checks=False):
        """
        Repair any inconsistent approximation rules.
        """
        self.calc_parents()
    
        while True:
            changed = False
            for node in self.all_nodes():
                try:
                    node.check_consistency_recurse(compiler_params)
                except NoApprox:
                    node.approx = random.choice(always_valid_approx_modes)
                    changed = True
            if not changed:
                break
    
        if more_checks:
            f1 = lambda: self.check_consistency(compiler_params, check_to_approx=True, check_recurse=False)
            f2 = lambda: self.check_consistency(compiler_params, check_to_approx=False, check_recurse=True)
            e1 = util.trap_exception_or_none(f1)
            e2 = util.trap_exception_or_none(f2)
            if type(e1) != type(e2):
                print('exception mismatch:', self, (e1, e2, self.allows_approx()))
                try:
                    f1()
                except:
                    traceback.print_exc()
                try:
                    f2()
                except:
                    traceback.print_exc()
                sys.exit(1)
            
            if e2 is not None:
                raise e2
        else:
            self.check_consistency(compiler_params)

    def all_approx_nodes(self, order='bfs'):
        return [n for n in self.all_nodes_order(order) if n.allows_approx()]

    def set_approx_recurse(self, approx):
        """
        Set approx for all nodes recursively to the given target.
        """
        for node in self.all_approx_nodes():
            node.approx = approx

    def set_approx(self, approx):
        if self.allows_approx():
            self.approx = approx

    def get_approx_recurse(self):
        """
        Get list of all approx modes recursively used in the Expr tree.
        """
        return list(set(node.approx for node in self.all_approx_nodes()))

    def as_approx_recurse(self, approx):
        """
        A copy of self that has approx set for all nodes recursively set to the given target.
        """
        ans = copy.deepcopy(self)
        ans.set_approx_recurse(approx)
        return ans

    def either_name(self, compiler_params):
        """
        Get variable name.
        """
        return self.var_name(compiler_params)
        
    def var_name(self, compiler_params):
        ans = compiler_params.get_varname(getattr(self, 'name', ''), id(self), self.dtype)
        if compiler_params.verbose >= 2:
            print('var_name:', repr(self), compiler_params, ans)
        return ans
    
    def to_source_expr(self, compiler_params):
        """
        Convert a side-effect free expression to source code.
        """
        raise NotImplementedError(self.__class__)

    def gradient(self, compiler_params):
        """
        Return a tuple of Exprs for gradient with respect to all children.
        
        To avoid redundant compute, the gradient should not make copies of sub-nodes: it should share instances
        with the original compute graph.
        """
        return tuple([ConstExpr(1.0) for i in range(5)])
        raise NotImplementedError

    def has_param_parents(self):
        """
        Return bool indicating whether any of the parents of self are VarParam instances.
        """
        return any([isinstance(parent, VarParam) for parent in self.parents])
    
    def debug(self, compiler_params):
        if compiler_params.verbose >= 2:
            print(self.__class__.__name__ + '.to_source (call)', compiler_params, repr(self))
    
    def debug_return(self, compiler_params, retval):
        if retval is None:
            if compiler_params.verbose >= 2:
                print('repr(self):', repr(self))
            raise ValueError
        if compiler_params.verbose >= 2:
            print(self.__class__.__name__ + '.to_source (ret) ', compiler_params, '|', retval, '|')
        return retval
    
    def is_inline(self, compiler_params):
        if compiler_params.mode == MODE_SAMPLE_PROBLEM:
            return False
        elif compiler_params.mode in [MODE_INLINE, MODE_ALWAYS_INLINE]:
            return self.dtype == INT_TYPE
        return False
    
    def to_source_inline(self, compiler_params):
        if compiler_params.mode in [MODE_VARNAME, MODE_SAMPLE_PROBLEM, MODE_INLINE, MODE_ALWAYS_INLINE]:
            if compiler_params.mode == MODE_SAMPLE_PROBLEM and compiler_params.root:
                return ''
            return self.to_source_impl(compiler_params.deroot().as_mode(MODE_INLINE if compiler_params.mode != MODE_ALWAYS_INLINE else MODE_ALWAYS_INLINE))
        elif compiler_params.mode == MODE_SIDE_EFFECTS:
            return ''
        else:
            raise ValueError('unknown mode', compiler_params.mode)
    
    def to_source(self, compiler_params):
        self.debug(compiler_params)
        if self.is_inline(compiler_params):
            ans = self.to_source_inline(compiler_params)
        else:
            ans = self.to_source_impl(compiler_params)
            ans = self.debug_return(compiler_params, ans)
        return ans
    
    def to_source_recurse(self, compiler_params, ans):
        if not compiler_params.recurse:
            return ''
        cp = compiler_params.deroot().as_mode(MODE_SIDE_EFFECTS)
        children = [child for child in self.children if isinstance(child, Expr)]
        if self.recurse_to_source_indices is not None:
            children = children[self.recurse_to_source_indices]
        prepend = ''
        for child in children:
            if not cp.recurse:
                sub = child.to_source_recurse(compiler_params, '')
                if len(sub):
                    prepend = prepend + '\n' + sub
            sub = child.to_source(cp)
            if len(sub):
                prepend = prepend + '\n' + sub
        return prepend + '\n' + ans
    
    def to_source_rhs(self, compiler_params, ordinary_value):
        if extra_verbose:
            print_header('to_source_rhs:')
            pprint.pprint(self)
        side_effectsL = []
        is_gradient = False
        rhs = ordinary_value
        ans = (rhs, '\n'.join(side_effectsL))
        if compiler_params.verbose >= 1 or extra_verbose:
            print_header('to_source_rhs return, is_gradient: %d, self: '%is_gradient + str(id(self)))
            print(ans)
        return ans

    def concat_side_effects(self, compiler_params, ans, side_effects):
        if len(side_effects.strip()):
            ans = side_effects + '\n' + ans
            if compiler_params.verbose >= 1:
                print('ans after side_effects:', id(self))
                print(ans)
        return ans
    
    def statement_id(self, compiler_params):
        """
        Get an "id" key for the set CompilerParams.statement_ids.
        """
        return id(self)
    
    def to_source_impl(self, compiler_params):
        """
        Convert to source code in the given language.
        
        In the base class this assumes a side-effect free expression is used, and implemented in to_source_expr().
        However, this behavior can be overridden by implementing a different to_source() in subclasses.
        """
        if compiler_params.mode == MODE_VARNAME:
            return self.either_name(compiler_params)
        elif compiler_params.mode in [MODE_SAMPLE_PROBLEM, MODE_INLINE, MODE_ALWAYS_INLINE]:
            if compiler_params.root and compiler_params.mode != MODE_ALWAYS_INLINE:
                return ''
            else:
                key = id(self)
                if key in compiler_params.cache_to_source:
                    return compiler_params.cache_to_source[key]
                ans = self.to_source_expr(compiler_params.deroot())
                compiler_params.cache_to_source[key] = ans
                return ans
        elif compiler_params.mode == MODE_SIDE_EFFECTS:
            self_id = self.statement_id(compiler_params)
            if self_id in compiler_params.statement_ids and no_generate_duplicates:
                return ''
            compiler_params.statement_ids.add(self_id)
            (rhs, side_effects) = self.to_source_rhs(compiler_params, self.to_source_expr(compiler_params.deroot().as_mode(MODE_VARNAME)))
            if compiler_params.verbose >= 1 or extra_verbose:
                print('to_source_impl to_source_rhs, id:', id(self), 'statement_id:', repr(self_id))
                print('to_source_impl returns:', id(self), (rhs, side_effects))
            ans = ''
            ans += '\n' + side_effects + '\n'
            ans += '\n' + self.to_source_recurse(compiler_params, '')
            
            def ljust(s):
                return (s).ljust(50)
            
            rhs += ';'
            rhs_comment = ' // Expr, id: ' + str(id(self)) + ', Linenos for Expr: ' + str(self.frame_lineno) + ', Linenos for codegen: ' + str(linenos_from_frame(inspect.currentframe()))

            if self.dtype != VOID_TYPE:
                ans += '\n' + ljust(self.dtype + ' ' + self.either_name(compiler_params) + ' = ' + rhs) + rhs_comment
            else:
                ans += '\n' + ljust(rhs) + rhs_comment
            if extra_verbose:
                print_header('to_source_impl ans:')
                print(ans)
                print_header('done to_source_impl ans')
            return ans
        else:
            raise ValueError('unhandled mode', compiler_params.mode)
    
    def repr(self, extra_info=True, cache=None, infix=False):
        if infix:
            return infix_repr(self)
        if cache is None:
            cache = dict()
        cache_key = id(self)
        if cache_key in cache:
            extra_s = ''
            if extra_info:
                extra_s = 'id: ' + str(id(self)) + ', '
            return self.__class__.__name__ + '(%srepeated %s)' % (extra_s, cache[cache_key])
        
        line_length = 80
        sub_repr = [x.repr(extra_info, cache) if hasattr(x, 'repr') else repr(x) for x in self.children]
        sub_repr_len = sum([len(x) for x in sub_repr])

        if extra_info:
            if hasattr(self, 'parents'):        # If calc_parents() called, include extra info in repr().
                sub_repr = ['parents: [' + ', '.join(str(id(p)) for p in self.parents) + ']'] + sub_repr
            sub_repr = ['id: ' + str(id(self))] + sub_repr

        if self.approx_rho_const is not None:
            sub_repr = ['approx_rho_const: ' + str(self.approx_rho_const)] + sub_repr
        if self.approx_rho != APPROX_RHO_ZERO:
            sub_repr = ['approx_rho: ' + str(self.approx_rho)] + sub_repr
        if extra_info:
            sub_repr = (['approx: ' + repr(self.approx)] if self.allows_approx() else []) + sub_repr
        if sub_repr_len < line_length and all([not hasattr(node, 'children') or node.children == [] or isinstance(node, ConstExpr) for node in self.children]):
            ans = self.__class__.__name__ + '(' + (', '.join(sub_repr)) + ')'
        else:
            ans = self.__class__.__name__ + '(\n' + indent(',\n'.join(sub_repr)) + '\n)'

        cache[cache_key] = hashlib.md5(ans.encode('utf-8')).hexdigest()

        return ans

    def __repr__(self):
        return self.repr()
    
    def __str__(self):
        return self.__class__.__name__
    
    def __iadd__(self, other):
        assert self.reduce is None
        self.reduce = '+'
        self.reduce_value = to_expr(other)
        return self
    
    def is_seq(self, other):
        return hasattr(self, '__len__') or hasattr(other, '__len__')
    
    def __add__(self, other):
        if self.is_seq(other):
            return numpy.add(self, other)
        return BinaryOp('+', self, other)

    def __radd__(self, other):
        if self.is_seq(other):
            return numpy.add(self, other)
        return BinaryOp('+', other, self)

    def __mul__(self, other):
        if self.is_seq(other):
            return numpy.multiply(self, other)
        return BinaryOp('*', self, other)

    def __rmul__(self, other):
        if self.is_seq(other):
            return numpy.multiply(self, other)
        return BinaryOp('*', other, self)

    def __mod__(self, other):
        if self.is_seq(other):
            return numpy.mod(self, other)
        return BinaryOp('%', self, other)

    def __rmod__(self, other):
        if self.is_seq(other):
            return numpy.mod(other, self)
        return BinaryOp('%', other, self)
    
    def __truediv__(self, other):
        if self.is_seq(other):
            return numpy.true_divide(self, other)
        return BinaryOp('/', self, other)

    def __rtruediv__(self, other):
        if self.is_seq(other):
            return numpy.true_divide(other, self)
        return BinaryOp('/', other, self)

    def __floordiv__(self, other):
        if self.is_seq(other):
            return numpy.floor_divide(self, other)
        return BinaryOp('/', self, other)

    def __rfloordiv__(self, other):
        if self.is_seq(other):
            return numpy.floor_divide(other, self)
        return BinaryOp('/', other, self)

    def __sub__(self, other):
        if self.is_seq(other):
            return numpy.subtract(self, other)
        return BinaryOp('-', self, other)

    def __rsub__(self, other):
        if self.is_seq(other):
            return numpy.subtract(other, self)
        return BinaryOp('-', other, self)

    def __neg__(self):
        return UnaryOp('-', self)

    def __pos__(self):
        return self

    def __pow__(self, other):
        if self.is_seq(other):
            return numpy.power(self, other)
        if isinstance(other, int_types + float_types):
            if other == 1:
                return self
            elif other == 0:
                return 1.0
        return BinaryOp('**', self, other)

    def __rpow__(self, other):
        if self.is_seq(other):
            return numpy.power(other, self)
        return BinaryOp('**', other, self)

    def __lt__(self, other):
        if continuous_comparisons:
            return gt0(other - self)
        else:
            return BinaryOp('<', self, other)

    def __le__(self, other):
        if continuous_comparisons:
            return ge0(other - self)
        else:
            return BinaryOp('<=', self, other)

    def __eq__(self, other):
        return BinaryOp('==', self, other)

    def __ne__(self, other):
        return BinaryOp('!=', self, other)

    def __gt__(self, other):
        if continuous_comparisons:
            return gt0(self - other)
        else:
            return BinaryOp('>', self, other)

    def __ge__(self, other):
        if continuous_comparisons:
            return ge0(self - other)
        else:
            return BinaryOp('>=', self, other)

    def __abs__(self):
        return Func('abs',
                    lambda x: (sign(x[0]),),
                    expectation_variance_functor(bandlimited_gaussian_abs, bandlimited_gaussian_abs2),
                    interval_lambda=lambda x: interval_abs(x[0]))(self)

class AlwaysInlineExpr(Expr):
    """
    Expression that is always generated inline. Subclasses should implement to_source_impl() method.
    """
    def to_source_impl(self, compiler_params):
        raise NotImplementedError
    
    def is_inline(self, compiler_params):
        return True

class ConstExpr(AlwaysInlineExpr):
    def allows_approx(self):
        return False
    
    def __init__(self, value):
        super().__init__()
        self.value = value
        if isinstance(value, int_types):
            self.dtype = INT_TYPE
        elif isinstance(value, float_types):
            self.dtype = REAL_TYPE
        elif isinstance(value, ConstExpr):
            self.value = value.value
            self.dtype = value.dtype
        elif isinstance(value, str):
            self.value = value
            self.dtype = STR_TYPE
            self.interval = interval.interval[-inf, inf]
        else:
            raise ValueError('unknown type')
        self.children = [self.value]
        if not hasattr(self, 'interval') or not interval_finite(self.interval) and isinstance(self.value, (int_types, float_types)):
            self.interval = interval.interval[value]

    def differentiate_wrt(self):
        if isinstance(self.value, str):
            return False
        return True
        
    def to_expectation_variance_impl(self, compiler_params):
        return self.to_expectation_variance_const()

    def repr(self, extra_info=True, cache=None):
        return str(self.value)
    
    def __str__(self):
        return super().__str__() + '(' + str(self.value) + ')'
    
    def to_source_impl(self, compiler_params):
        return repr(self)

def gen_attrs(assign_lambdas):
    ans = []
    for (i, assign_lambda) in enumerate(assign_lambdas):
        def append_setter(i, assign_lambda):
            def setter(self, value):
                self.children[i] = assign_lambda(value)
            ans.append(property(lambda self: self.children[i], setter))
        append_setter(i, assign_lambda)
    return ans

class Var(Expr):
    """
    A variable that is assigned initially, and possibly added to with a reduction expression.
    """
    def __init__(self, name, initial_value=0.0, reduce=None, reduce_value=None, is_argument=False):
        """
        Here reduce is a string for the reduction operator (e.g. '+') or None if no reduction.
        """
        super().__init__()
        self.children = [str(name), to_expr(initial_value), reduce, reduce_value]
        self.dtype = self.initial_value.dtype
        self.interval = self.initial_value.interval
        self.is_argument = is_argument
        if reduce is not None:
            self.interval = infinite_interval()
    
    (name, initial_value, reduce, reduce_value) = gen_attrs([str, to_expr, str, to_expr])

    def allows_approx(self):
        # Vars do not have separate approximation rules: they inherit their approximation behavior from their values (self.initial_value and self.reduce_value)
        return False

    def to_expectation_variance_impl(self, compiler_params):
        initial_value_EV = self.initial_value.to_expectation_variance(compiler_params)
        if self.reduce is None:
            return (Var(self.name, initial_value_EV[0]), Var(self.name + '_var', initial_value_EV[1]))
        else:
            reduce_value_EV = self.reduce_value.to_expectation_variance(compiler_params)
            return (Var(self.name, initial_value_EV[0], self.reduce, reduce_value_EV[0], self.is_argument), ConstExpr(0.0))
    
    def to_source_impl(self, compiler_params):
        full_name = self.either_name(compiler_params)
        if compiler_params.mode == MODE_VARNAME:
            return full_name
        elif compiler_params.mode == MODE_ALWAYS_INLINE:
            if self.reduce is not None:
                raise ValueError('cannot convert reduction to source code in mode MODE_ALWAYS_INLINE')
            return self.initial_value.to_source(compiler_params)
        elif compiler_params.mode in [MODE_SAMPLE_PROBLEM, MODE_INLINE]:
            if compiler_params.mode == MODE_ALWAYS_INLINE:
                return full_name
            return ''
        elif compiler_params.mode == MODE_SIDE_EFFECTS:
            if self.is_argument:
                return ''
            self_id = self.statement_id(compiler_params)
            if self_id in compiler_params.statement_ids and no_generate_duplicates:
                return ''
            compiler_params.statement_ids.add(self_id)
            if self.reduce is not None:
                iv_side_effects = self.initial_value.to_source(compiler_params)
                iv_rhs = self.initial_value.to_source(compiler_params.deroot().as_mode(MODE_VARNAME))
                ans_children = self.to_source_recurse(compiler_params, '')
                ans_self = full_name + ' += ' + self.reduce_value.to_source(compiler_params.deroot().as_mode(MODE_VARNAME)) + ';'
                ans = ans_children + '\n' + ans_self
                ans = iv_side_effects + '\n' + self.dtype + ' ' + full_name + ' = ' + iv_rhs + ';\n' + ans
                return ans
            else:
                ans = self.var_initializer(compiler_params.as_mode(MODE_VARNAME)) #self.dtype + ' ' + self.name + node_to_source(self.initial_value, compiler_params) + ';'
                ans = self.to_source_recurse(compiler_params, ans)
                if compiler_params.trace:
                    ans += '\nprintf("' + full_name + ': %e\\n", ' + full_name + ');\n'
                return ans
        else:
            raise ValueError('unhandled mode', compiler_params.mode)

    def arg_declare(self, compiler_params):
        return self.dtype + ' ' + self.either_name(compiler_params)
    
    def var_initializer(self, compiler_params):
        if compiler_params.mode in [MODE_SAMPLE_PROBLEM, MODE_INLINE, MODE_ALWAYS_INLINE]:
            name = self.name
            declare = ''
        else:
            name = self.either_name(compiler_params)
            declare = self.dtype + ' '
        if compiler_params.verbose >= 2:
            print('var_initializer:', repr(self), compiler_params, name)
            print('var_initializer to_source_rhs')
        (initial_value, side_effects) = self.to_source_rhs(compiler_params, self.initial_value.to_source(compiler_params))# + repr((compiler_params.root,
        if compiler_params.verbose >= 2:
            print('var_initializer to_source_rhs returns')
        if compiler_params.verbose >= 2:
            print(repr((declare, name, initial_value)))
        ans = '\n' + '// Side effects (forward, variable initializer)\n' + side_effects
        ans += '\n' + declare + name + ' = ' + initial_value + '; // var initializer, id: ' + str(id(self))

        return ans

class VarParam(Var):
    """
    Variable parameter that can be set before calling the solver.
    """
    def to_expectation_variance_impl(self, compiler_params):
        return self.to_expectation_variance_const()
    
    def to_source_impl(self, compiler_params):
        if compiler_params.mode in [MODE_VARNAME, MODE_INLINE, MODE_ALWAYS_INLINE]:
            return compiler_params.get_varname(self.name, self.name, self.dtype, True)
        elif compiler_params.mode == MODE_SIDE_EFFECTS:
            return ''
        elif compiler_params.mode == MODE_SAMPLE_PROBLEM:
            return self.var_initializer(compiler_params.deroot())
        else:
            raise ValueError('unhandled mode', compiler_params.mode)

class ArgumentArray(AlwaysInlineExpr):
    def __init__(self, name=DEFAULT_ARGUMENT_ARRAY_NAME, dtype=VECTOR_TYPE, initializer=None, bounds=(-inf, inf), ndims=4):
        """
        Bounds can be either a single tuple (lo, hi), or a list of tuples, one for each dimension.
        """
        super().__init__()
        self.ndims = ndims
        self.children = [str(name)]
        self.dtype = dtype
        self.initializer = initializer
        if self.initializer is not None:
            self.interval = self.initializer.interval
        if isinstance(bounds[0], tuple):
            self.bound_list = bounds
            bounds = (builtin_min([bounds[i][0] for i in range(ndims)]), builtin_max([bounds[i][1] for i in range(ndims)]))
        else:
            self.bound_list = [bounds for i in range(ndims)]
        if bounds != (-inf, inf):
            self.bound(*bounds)

    def allows_approx(self):
        return False
    
    (name,) = gen_attrs([str])
    
    def __getitem__(self, index):
        return GetItem(self, index)

    def size(self):
        return GetSize(self)

    def to_source_inline(self, compiler_params):
        if self.name != DEFAULT_ARGUMENT_ARRAY_NAME:
            if compiler_params.mode == MODE_SAMPLE_PROBLEM:
                if self.initializer is not None:
                    return self.name + ' = ' + self.initializer.to_source(compiler_params.deroot()) + ';'
        return AlwaysInlineExpr.to_source_inline(self, compiler_params)
        
    def to_source_impl(self, compiler_params):
        if self.name not in [DEFAULT_ARGUMENT_ARRAY_NAME, OUTPUT_ARRAY]:
            compiler_params.instance_dtype[self.name] = self.dtype
        return self.name

class Tuple(AlwaysInlineExpr):
    """A tuple that can be used only for indexing currently."""
    def __init__(self, t):
        super().__init__()
        self.children = [to_expr(e) for e in t]
        self.dtype = self.children[0].dtype
    
    def to_source_impl(self, compiler_params):
        return ','.join(e.to_source(compiler_params) for e in self.children)

class GetItem(Expr):
    def __init__(self, array, index):
        super().__init__()
        self.children = [to_expr(array), to_expr(index)]
        self.dtype = REAL_TYPE
        self.interval = array.interval
    
    def allows_approx(self):
        return self.array.allows_approx()

    (array, index) = gen_attrs([to_expr, to_expr])

    def to_expectation_variance_impl(self, compiler_params):
        if is_unknown_array(self.array):
            return (self, compiler_params.sigma[self.index]**2)
        else:
            return self.to_expectation_variance_const()

    def to_source_expr(self, compiler_params):
        if compiler_params.verbose >= 2:
            print('repr(self.array):', repr(self.array), 'repr(self.index):', repr(self.index))
        (lbrace, rbrace) = ('[', ']')
        if is_matrix(self.array.dtype):
            (lbrace, rbrace) = ('(', ')')
        return self.array.to_source(compiler_params) + lbrace + self.index.to_source(compiler_params) + rbrace

    def to_source_impl(self, compiler_params):
        return Expr.to_source_impl(self, compiler_params)

class GetSize(Expr):
    def __init__(self, array):
        super().__init__()
        self.children = [to_expr(array)]
        self.dtype = INT_TYPE
    
    (array,) = gen_attrs([to_expr])
    
    def to_source_expr(self, compiler_params):
        return self.array.to_source(compiler_params) + '.size()'

class Func(Expr):
    def __init__(self, name, gradient_lambda, to_expectation_variance_gaussian_lambda=None, interval_lambda=None, allows_approx_bool=True):
        super().__init__()
        self.children = [str(name)]
        self.gradient_lambda = gradient_lambda
        self.to_expectation_variance_gaussian_lambda = to_expectation_variance_gaussian_lambda
        self.interval_lambda = interval_lambda
        self.allows_approx_bool = allows_approx_bool
    
    (name,) = gen_attrs([to_expr])
    
    def __call__(self, *args):
        return Call(self.name, *args, gradient_lambda=self.gradient_lambda, to_expectation_variance_gaussian_lambda=self.to_expectation_variance_gaussian_lambda, interval_lambda=self.interval_lambda, allows_approx_bool=self.allows_approx_bool)
    
    def to_source_expr(self, compiler_params):
        raise ValueError('Func should be called before conversion to source')

class Call(Expr):
    def __init__(self, name, *args, gradient_lambda=None, to_expectation_variance_gaussian_lambda=None, interval_lambda=None, allows_approx_bool=True):
        super().__init__()
        self.children = [str(name)] + [to_expr(a) for a in args]
        self.dtype = REAL_TYPE
        self.gradient_lambda = gradient_lambda
        self.to_expectation_variance_gaussian_lambda = to_expectation_variance_gaussian_lambda
        self.interval_lambda = interval_lambda
        self.allows_approx_bool = allows_approx_bool
        if interval_lambda is not None:
            self.interval = self.interval_lambda([child.interval for child in self.children[1:]])

    def allows_approx(self):
        return self.allows_approx_bool and Expr.allows_approx(self)
    
    def to_expectation_variance_gaussian(self, compiler_params):
        if self.to_expectation_variance_gaussian_lambda is None:
            raise NotImplementedError('to_expectation_variance_gaussian_lambda not supplied to Func, self=%r'%self)

        child_EV = []
        for child in self.children[1:]:
            child_EV.append(child.to_expectation_variance(compiler_params))
    
        return self.to_expectation_variance_gaussian_lambda(self, *tuple(child_EV))
    
    (name,) = gen_attrs([to_expr])

    def to_source_impl(self, compiler_params):
        return Expr.to_source_impl(self, compiler_params)
    
    def to_source_expr(self, compiler_params):
        return self.name + '(' + ','.join([a.to_source(compiler_params) for a in self.children[1:]]) + ')'

    def gradient(self, compiler_params):
        return self.gradient_lambda([a for a in self.children[1:]])

def numerical_promote(a, b):
    if a == REAL_TYPE or b == REAL_TYPE:
        return REAL_TYPE
    else:
        return a

def is_any_constant(b_str):
    try:
        b_val = eval(b_str)
        return True
    except:
        return False

def is_all_constant(e):
    return all(isinstance(node, (ConstExpr, BinaryOp, UnaryOp)) for node in e.all_nodes_generator())

def is_constant(b_str, b_value):
    eps = 1e-15
    try:
        b_val = eval(b_str)
        diff = b_val - b_value
    except:
        return False
    
    ans = abs(b_val - b_value) <= eps
    return ans

def constant_value(b_str):
    ans = eval(b_str)
    return to_expr(ans)

class BinaryOp(Expr):
    def __init__(self, op, a, b):
        super().__init__()
        self.children = [str(op), to_expr(a), to_expr(b)]
        self.dtype = numerical_promote(self.children[1].dtype, self.children[2].dtype)
        assert isinstance(self.a, Expr)
        assert isinstance(self.b, Expr)
    
        if self.op == '*':
            self.interval = self.a.interval * self.b.interval
        elif self.op == '+':
            self.interval = self.a.interval + self.b.interval
        elif self.op == '-':
            self.interval = self.a.interval - self.b.interval
        elif self.op == '/':
            self.interval = self.a.interval / self.b.interval
        elif self.op == '%':
            self.interval = interval.interval[0.0, interval_bounds(self.b.interval)[1]]
        elif self.op == '**':
            b_int = self.integer_power(CompilerParams())         # Python interval library currently supports only integer powers
            if b_int is not None:
                self.interval = self.a.interval ** b_int
        self.channel = get_channel(self.a, self.b)
        
    (op, a, b) = gen_attrs([str, to_expr, to_expr])

    def __str__(self):
        return super().__str__() + '(' + self.op + ')'

    def allows_approx_rho(self):
        return self.op in ['+', '-', '*', '/']

    def simplify_impl(self):
        cp = CompilerParams()
        a = self.a_str(cp)
        b = self.b_str(cp)
        if self.op == '*':
            if is_constant(b, 1.0):
                return self.a
            elif is_constant(a, 1.0):
                return self.b
            elif is_constant(b, 0.0) or is_constant(a, 0.0):
                return ConstExpr(0.0)
        
            def handle_mul_mul_const(a_expr, b_expr, a_str):
                if is_any_constant(a_str) and isinstance(b_expr, BinaryOp) and b_expr.op == '*':
                    b_a = b_expr.a_str(cp)
                    b_b = b_expr.b_str(cp)
                    if is_any_constant(b_a):
                        return to_expr(constant_value(a_str).value * constant_value(b_a).value) * b_expr.b
                    if is_any_constant(b_b):
                        return to_expr(constant_value(a_str).value * constant_value(b_b).value) * b_expr.a
    
            arg_list = [(self.a, self.b, a), (self.b, self.a, b)]
            if isinstance(self.b, Var) and self.b.reduce is None:
                arg_list.append((self.a, self.b.initial_value, a))
            if isinstance(self.a, Var) and self.a.reduce is None:
                arg_list.append((self.b, self.a.initial_value, b))
            for (a_expr, b_expr, a_str) in arg_list:
                v1 = handle_mul_mul_const(a_expr, b_expr, a_str)
                if v1 is not None:
                    return v1
        elif self.op == '/':
            if is_constant(b, 1.0):
                return self.a
        elif self.op == '+':
            if is_constant(a, 0.0):
                return self.b
            elif is_constant(b, 0.0):
                return self.a
        elif self.op == '-':
            if is_constant(b, 0.0):
                return self.a
        elif self.op == '**':
            if is_constant(b, 1.0):
                return self.a
            if is_constant(a, 0.0):
                if is_any_constant(b):
                    bval = constant_value(b).value
                    if bval > 0.0:
                        return to_expr(0.0)
            if is_constant(b, 0.5):
                ap_L = [self.a]
                if isinstance(self.a, Var):
                    ap_L.append(self.a.initial_value)
                for ap in ap_L:
                    if isinstance(ap, BinaryOp) and ap.op == '*' and ap.a.identical(ap.b):
                        return ap.a
                    if isinstance(ap, BinaryOp) and ap.op == '**' and is_constant(ap.b_str(cp), 2.0):
                        return ap.a

        if not is_all_constant(self):
            return self

        self_str = self.to_source(cp.as_mode(MODE_ALWAYS_INLINE))
        try:
            ans = constant_value(self_str)
            if ans is not None:
                return ans
        except:
            pass

        return self
    
    def optional_simplify(self, E_var, do_simplify):
        (E, var) = E_var
        if not do_simplify:
            return (E, var)
        return (simplify(E), simplify(var))
        
    def to_expectation_variance_gaussian(self, compiler_params, do_simplify=False):
        if compiler_params.verbose >= 1 and extra_verbose:
            print('BinaryOp.to_expectation_variance_gaussian')
            print('BinaryOp.to_expectation_variance_gaussian, approx_rho=', self.approx_rho)
            print('BinaryOp.to_expectation_variance_gaussian, approx_rho_const=', self.approx_rho_const)
        (a_E, a_var) = self.a.to_expectation_variance(compiler_params)
        (b_E, b_var) = self.b.to_expectation_variance(compiler_params)
        if compiler_params.verbose >= 1 and extra_verbose:
            print('BinaryOp.to_expectation_variance_gaussian, got a and b E and var')

        b_int = self.integer_power(compiler_params)
        
        if compiler_params.verbose >= 1 and extra_verbose:
            print('BinaryOp.to_expectation_variance_gaussian, got b_int', b_int)
        if self.is_power(compiler_params, 1.0):
            return (a_E, a_var)
        elif b_int is not None and b_int >= 1:
            if isinstance(self.a, Call):
                key = (self.a.name, b_int)
                if key in func_powers:
                    if len(self.a.children[1:]) == 1:
                        (child_E, child_var) = self.a.children[1].to_expectation_variance(compiler_params)
                        return func_powers[key](self, (child_E, child_var))
        
            E = bandlimit_poly.bandlimit_poly(b_int, var=True)(a_E, a_var)
            if compiler_params.verbose >= 2:
                print_header('E before simplify:')
                pprint.pprint(E)
            if compiler_params.verbose >= 2:
                print_header('E after simplify:')
                pprint.pprint(E)
            var = max(bandlimit_poly.bandlimit_poly(b_int*2, var=True)(a_E, a_var) - E**2, 0.0) #(4.0 * a_E**2 + 2.0) * a_var

            return self.optional_simplify((E, var), do_simplify)

        b_float = self.float_power(compiler_params)
        if compiler_params.verbose >= 1 and extra_verbose:
            print('BinaryOp.to_expectation_variance_gaussian, got b_float', b_float)
        
        if b_float is not None:
            if b_int is not None:           # Negative integer power
                is_int = True
                dist_to_singularity = abs(a_E)
            else:                           # Fractional power
                is_int = False
                dist_to_singularity = max(a_E, 0.0)
            lambda_dist = 0.5
            if isinstance(a_var, BinaryOp) and a_var.is_power(compiler_params, 2):
                a_sigma = a_var.a
                r3t = (3.0)**0.5 * min(a_sigma, dist_to_singularity*lambda_dist)
                t_used = r3t**2
            else:
                t_used = min(a_var, dist_to_singularity**2*lambda_dist**2)
                r3t = sqrt(t_used*3.0)

            r3t = max(r3t, 1e-8)
                
            def box_bandlimited_pow(p):
                if p == -1:
                    if prefer_tent_pow:
                        return bandlimited_tent_functor((a_E, a_var), lambda x: 1.0/x, lambda x: x*(log(x)-1.0))
                    else:
                        return select_variance(t_used > 0.0, 0.5 / r3t * log((a_E+r3t) / (a_E-r3t)), a_E**p)
                elif p == -2:
                    if prefer_tent_pow:
                        return bandlimited_tent_functor((a_E, a_var), lambda x: 1.0/x**2, lambda x: -log(x))
                    else:
                        return select_variance(t_used > 0.0, 1.0 / (a_E**2 - 3 * t_used), a_E**p)
                p1 = p + 1
                return select_variance(t_used > 0.0, (0.5 / (p1)) / r3t * ((a_E+r3t)**p1 - (a_E-r3t)**p1), a_E**p)

            E = box_bandlimited_pow(b_float)

            var = max(box_bandlimited_pow(b_float*2) - E**2, 0.0)

            return self.optional_simplify((E, var), do_simplify)

        if compiler_params.verbose >= 1 and extra_verbose:
            print('BinaryOp.to_expectation_variance_gaussian, done handling power')

        a_str = self.a_str(compiler_params)
        b_str = self.b_str(compiler_params)

        if compiler_params.verbose >= 1 and extra_verbose:
            print('BinaryOp.to_expectation_variance_gaussian, done calculating a_str and b_str')

        covar = 0.0    # Covar(a, b) = sqrt(a_var * b_var) * rho
        rho = 0.0      # corr(a, b)
        needs_covar = False
        needs_rho = False
        
        if self.a.identical(self.b):
            rho = 1.0
            covar = a_var

        if compiler_params.verbose >= 1 and extra_verbose:
            print('BinaryOp.to_expectation_variance_gaussian, done calculating covar')

        if self.approx_rho == APPROX_RHO_CONSTANT:
            if self.approx_rho_const is not None:
                rho = self.approx_rho_const
            needs_covar = True
        
        if compiler_params.verbose >= 1 and extra_verbose:
            print('BinaryOp.to_expectation_variance_gaussian, handled APPROX_RHO_CONSTANT case')

        if self.approx_rho == APPROX_RHO_GRADIENT:
            if compiler_params.verbose:
                print('APPROX_RHO_GRADIENT found')
            rho = self.approx_rho_gradient(compiler_params)
            if compiler_params.log_approx_rho_gradient:
                compiler_params.log_approx_rho_gradient_list.append(rho)
            needs_covar = True

        if compiler_params.verbose >= 1 and extra_verbose:
            print('BinaryOp.to_expectation_variance_gaussian, handle APPROX_RHO_GRADIENT case')

        if self.approx_rho == APPROX_RHO_GRADIENT2:
            if compiler_params.verbose:
                print('APPROX_RHO_GRADIENT2 found')
            covar = self.approx_rho_gradient(compiler_params, compute_cov=True)
            if compiler_params.log_approx_cov_gradient:
                compiler_params.log_approx_cov_gradient_list.append(covar)
            needs_rho = True

        if compiler_params.verbose >= 1 and extra_verbose:
            print('BinaryOp.to_expectation_variance_gaussian, handle APPROX_RHO_GRADIENT2 case')

        if needs_covar:
            covar = rho * sqrt(a_var * b_var)

        if self.op == '*':
            if compiler_params.verbose >= 1 and extra_verbose:
                print('BinaryOp.to_expectation_variance_gaussian, handling *')

            if is_any_constant(a_str):
                return (self.a * b_E, self.a ** 2 * b_var)
            elif is_any_constant(b_str):
                return (a_E * self.b, a_var * self.b ** 2)

            Sigma11 = a_var
            Sigma22 = b_var

            E = a_E * b_E + covar
            
            if needs_rho:
                rho = covar / sqrt(a_var * b_var)
                rho = rho.simplify()
                
            var = a_E**2*Sigma22 + b_E**2*Sigma11 + 2*a_E*b_E*covar + Sigma11*Sigma22*(1+rho**2)
            
            return self.optional_simplify((E, var), do_simplify)

                    # Two sanity checks of the above formula:
                    #         For Y = X*X, mean is a_E**2 + covar, variance is 4*a_E**2*covar + 2*covar**2
                    #         This agrees with https://answers.yahoo.com/question/index?qid=20101127180607AAw7gm3
                    #         For Y = A*B with zero covariance, mean is a_E*b_E, variance is
                    #             a_E**2*b_var + b_E**2*a_var + a_var*b_var
                    #         This agrees with http://www.odelama.com/data-analysis/Commonly-Used-Math-Formulas/

        if self.op == '/':
            if compiler_params.verbose >= 1 and extra_verbose:
                print('BinaryOp.to_expectation_variance_gaussian, handling /')
            if is_any_constant(b_str):
                return self.optional_simplify((a_E / self.b, a_var / self.b ** 2), do_simplify)

            ans = copy.deepcopy(self.a * self.b**-1)
            ans.set_approx_recurse(self.approx)
            ans.approx_rho = self.approx_rho
            return ans.to_expectation_variance(compiler_params)

        if self.op == '+':
            if compiler_params.verbose >= 1 and extra_verbose:
                print('BinaryOp.to_expectation_variance_gaussian, handling +')
            E = a_E + b_E
            var = a_var + b_var + 2*covar
            return self.optional_simplify((E, var), do_simplify)

        if self.op == '-':
            if compiler_params.verbose >= 1 and extra_verbose:
                print('BinaryOp.to_expectation_variance_gaussian, handling -')
            return self.optional_simplify((a_E - b_E, a_var + b_var - 2*covar), do_simplify)
        
        if self.op == '%':
            if compiler_params.verbose >= 1 and extra_verbose:
                print('BinaryOp.to_expectation_variance_gaussian, handling %')
            fract_mode = getattr(self, 'approx_fract_mode', DEFAULT_FRACT_MODE)
            if tune_fract:
                E = b_E*bandlimited_fract(None, (a_E/b_E, a_var/b_E**2), fract_mode)
                var = b_E**2*bandlimited_fract2(None, (a_E/b_E, a_var/b_E**2), fract_mode) - E**2
            else:
                E = b_E*bandlimited_fract(None, (a_E/b_E, a_var/b_E**2))
                var = b_E**2*bandlimited_fract2(None, (a_E/b_E, a_var/b_E**2)) - E**2
            return self.optional_simplify((E, var), do_simplify)

        if self.op in ['<', '>', '<=', '>=', '==', '!=']:
            if compiler_params.verbose >= 1 and extra_verbose:
                print('BinaryOp.to_expectation_variance_gaussian, handling comparison')
            return (BinaryOp(self.op, a_E, b_E), BinaryOp(self.op, a_var, b_var))
        
        raise ValueError('not implemented', (self.op, self.a, self.b))

    def approx_rho_gradient(self, compiler_params, compute_cov=False):
        if compiler_params.verbose:
            print('approx_rho_gradient, self:', infix_repr(self))
        avars = [node for node in self.a.all_nodes() if node.is_unknown_getitem()]
        bvars = [node for node in self.b.all_nodes() if node.is_unknown_getitem()]
        vars = union_exprs(avars, bvars)
        if len(vars) == 0:
            print('Warning: zero variables used in APPROX_RHO_GRADIENT approximation')
            return to_expr(0.0)
        
        agrad = gradient(compiler_params, self.a, vars, allow_none=True)
        bgrad = gradient(compiler_params, self.b, vars, allow_none=True)
        assert len(agrad) == len(bgrad)
        
        if compute_cov is True:
            cov = sum([agrad[i]*bgrad[i]*compiler_params.sigma[vars[i].index] for i in range(len(vars))])
            cov = cov.simplify()
            return cov
        
        dot = sum([agrad[i]*bgrad[i] for i in range(len(agrad))])
        dot = dot.simplify()
        if compiler_params.verbose:
            print('approx_rho_gradient, agrad:', infix_repr(agrad))
            print('approx_rho_gradient, bgrad:', infix_repr(bgrad))
            
        anorm = sum([agrad[i]**2 for i in range(len(agrad))])
        bnorm = sum([bgrad[i]**2 for i in range(len(agrad))])
        denom = (anorm*bnorm)**0.5
        denom = denom.simplify()
        if compiler_params.verbose:
            print('approx_rho_gradient, denom:', infix_repr(denom))
        if dot.identical(to_expr(0.0)):
            ans = to_expr(0.0)
        elif isinstance(denom, ConstExpr):
            if denom.value == 0.0:
                ans = to_expr(0.0)
            else:
                ans = dot / denom
        else:
            ans = select(denom != 0.0, dot / denom, 0.0)
        ans = ans.simplify()
        if compiler_params.verbose:
            print('approx_rho_gradient, ans:', infix_repr(ans))
        return ans

    def a_str(self, compiler_params):
        if not is_all_constant(self.a):
            return ''
        if compiler_params.verbose >= 2:
            print_header('a_str:')
            pprint.pprint(self.a)
        ans = self.a.to_source(compiler_params.as_mode(MODE_ALWAYS_INLINE))
        return ans
        
    def b_str(self, compiler_params):
        if not is_all_constant(self.b):
            return ''

        if compiler_params.verbose >= 2:
            print_header('b_str:')
            pprint.pprint(self.b)
        ans = self.b.to_source(compiler_params.as_mode(MODE_ALWAYS_INLINE))
        if compiler_params.verbose >= 2:
            print_header('b_str result:')
            print(ans)
        return ans
    
    def is_power(self, compiler_params, b_const, b=None):
        if b is None:
            b = self.b_str(compiler_params)
        if compiler_params.verbose >= 2:
            print('is_power', b, b_const)
        if not self.op == '**':
            return False
        return is_constant(b, b_const)

    def integer_power(self, compiler_params, allow_float=False):
        """
        Gets int for power if it is an integer otherwise returns None.
        """
        if self.op != '**':
            return None
        b = self.b_str(compiler_params)
        try:
            b_val = eval(b)
        except:
            return None
        if allow_float and isinstance(b_val, int_types + float_types):
            return b_val
        if b_val == int(b_val):
            return int(b_val)
        return None

    def float_power(self, compiler_params):
        return self.integer_power(compiler_params, True)
    
    def pow_str(self, compiler_params, a, b):
        b_str = self.b_str(compiler_params)
        if self.is_power(compiler_params, -1.0, b_str):
            return '(1.0/(' + a + '))'
        if self.is_power(compiler_params, 0.0, b_str):
            return '(1.0)'
        if self.is_power(compiler_params, 1.0, b_str):
            return '(' + a + ')'
        if self.is_power(compiler_params, 2.0, b_str):
            return '((' + a + ') * (' + a + '))'
        if self.is_power(compiler_params, 3.0, b_str):
            return '((' + a + ') * (' + a + ') * (' + a + '))'
        if self.is_power(compiler_params, 0.5, b_str):
            return 'sqrt(' + a + ')'
        if self.is_power(compiler_params, -0.5, b_str):
            return '(1.0/sqrt(' + a + '))'
        return 'pow(' + a + ', ' + b + ')'

    def to_source_expr(self, compiler_params):
        a = self.a.to_source(compiler_params)
        b = self.b.to_source(compiler_params)
        
        if compiler_params.log_rho and self.allows_approx_rho() and self.approx_rho_index >= 0:
            op_to_str = {'+': 'plus', '-': 'minus', '*': 'times', '/': 'divide'}
            op_str_name = op_to_str[self.op]
            return_value = 'log_rho_' + op_str_name + '(' + str(self.approx_rho_index) + ', ' + a + ',' + b + ')'
            return return_value
        
        if self.op == '**':
            return self.pow_str(compiler_params, a, b)
        elif self.op == '%':
            return 'fmod_round_down(' + a + ', ' + b + ')'
        else:
            return '((' + a + ')' + self.op + '(' + b + '))'

    def gradient(self, compiler_params):
        a = self.a
        b = self.b
        if self.op == '**':
            return (b * a ** (b-1), ConstExpr(1.0))     # TODO: last derivative is wrong.
        elif self.op == '*':
            return (b, a)
        elif self.op == '%':
            return (ConstExpr(1.0), b//a)
        elif self.op == '//':
            return (ConstExpr(0.0), ConstExpr(0.0))
        elif self.op == '-':
            return (ConstExpr(1.0), ConstExpr(-1.0))
        elif self.op == '+':
            return (ConstExpr(1.0), ConstExpr(1.0))
        elif self.op == '/':
            return (1.0/b, -a / b**2)
        elif self.op in ['<', '<=', '==', '>', '>=', '!=']:
            return (ConstExpr(0.0), ConstExpr(0.0))
        else:
            raise ValueError('gradient not implemented:', self.op)

class Compound(Expr):
    """
    Combines several expressions into a compound expression.
    """
    def __init__(self, L):
        super().__init__()
        self.children = [to_expr(x) for x in L]
        if len(self.children):
            self.dtype = self.children[-1].dtype
        else:
            self.dtype = VOID_TYPE
    
    def to_source_impl(self, compiler_params):
        if compiler_params.mode == MODE_VARNAME:
            return '0.0'
        else:
            return '\n'.join(e.to_source(compiler_params) for e in self.children)

    def to_expectation_variance_impl(self, compiler_params):
        return (Compound([child.to_expectation_variance(compiler_params)[0] for child in self.children]), ConstExpr(0.0))

class Assign(Expr):
    """
    Assigns lhs to rhs, with op optionally performing an in-place binary operation such as *= (op = '*'), += (op = '+'), etc.
    """
    def __init__(self, lhs, rhs, op=''):
        super().__init__()
        self.children = [to_expr(lhs), to_expr(rhs), str(op)]
        self.dtype = VOID_TYPE
        self.recurse_to_source_indices = slice(1, 2)
    
    (lhs, rhs, op) = gen_attrs([to_expr, to_expr, str])

    def to_source_expr(self, compiler_params):
        return self.lhs.to_source(compiler_params.as_mode(MODE_ALWAYS_INLINE)) + ' ' + self.op + '= ' + self.rhs.to_source(compiler_params)

    def to_expectation_variance_impl(self, compiler_params):
        return (Assign(self.lhs, self.rhs.to_expectation_variance(compiler_params)[0], self.op), ConstExpr(0.0))

class UnaryOp(Expr):
    def __init__(self, op, a):
        super().__init__()
        self.children = [str(op), to_expr(a)]
        self.dtype = self.a.dtype
        
        if self.op == '-':
            self.interval = -self.a.interval
        else:
            raise ValueError('operator not implemented: ', self.op)
            
        self.channel = self.a.channel

    (op, a) = gen_attrs([str, to_expr])

    def to_source_expr(self, compiler_params):
        return '(' + self.op + '(' + self.a.to_source(compiler_params) + '))'

    def to_expectation_variance_gaussian(self, compiler_params):
        (a_E, a_var) = self.a.to_expectation_variance(compiler_params)
        if self.op == '-':
            return (-a_E, a_var)
        else:
            raise ValueError('operator not implemented:', self.op)

    def gradient(self, compiler_params):
        a = self.a
        if self.op == '-':
            return (ConstExpr(-1.0),)
        else:
            raise ValueError('not implemented derivative:', self.op)

def bandlimited_sign(self, EV):
    (x, v) = EV
    sigma = sqrt(v)
    return erf(x / (sigma * 2**0.5))

def bandlimited_gaussian_cos(self, EV):
    (x, v) = EV
    return cos(x)*exp(-v/2.0)

def bandlimited_gaussian_sin(self, EV):
    (x, v) = EV
    return sin(x)*exp(-v/2.0)

def bandlimited_gaussian_exp(self, EV):
    (x, v) = EV
    return exp(x+v/2.0)

def bandlimited_gaussian_abs(self, EV):
    (x, v) = EV
    sigma = sqrt(v)
    return x * erf(x / (sigma * 2**0.5)) + sigma * ((2/numpy.pi)**0.5) * exp(-x * x / (2.0 * v))

def bandlimited_gaussian_abs2(self, EV):      # Same as bandlimiting of x^2
    (x, v) = EV
    return x**2 + v

def bandlimited_gaussian_cos2(self, EV):
    (x, v) = EV
    return 0.5 + 0.5 * cos(2*x)*exp(-v*2.0)

def bandlimited_gaussian_sin2(self, EV):
    (x, v) = EV
    return 0.5 - 0.5 * cos(2*x)*exp(-v*2.0)

def bandlimited_box_w(EV):
    v = EV[1]
    return 3**0.5 * v**0.5

def bandlimited_box_functor(EV, f, F, bounds=None, dist_to_singularity=None):
    (x, v) = EV
    r3t_orig = bandlimited_box_w(EV)
    if dist_to_singularity is None:
        r3t = r3t_orig
    else:
        r3t = min(r3t_orig, 0.5*dist_to_singularity(x))
    ans = select_variance(v > 0.0, 0.5*(F(x+r3t)-F(x-r3t))/(r3t+1e-8), f(x))
    if bounds is not None:
        ans.interval = interval.interval[bounds[0], bounds[1]]
    return ans

def bandlimited_tent_functor(EV, f, F, bounds=None):
    # Some comments from proj/csolver/func.cpp, function quadratic_filter_1d():
    # Box filter       (n=1): Var B = Var U[-w/2, w/2] = 1/12 * w^2            (Filter support: w)
    # Tent filter      (n=2): Var B*B = 2/12 * w^2                             (Filter support: 2w)
    # Quadratic filter (n=3): Var B*B*B = 3/12 * w^2                           (Filter support: 3w)
    #                         Stddev B*B*B = (1/2) w = sigma, w = 2 sigma, so filter support is 6 sigma.
    #                         Taps are [-1, 3, -3, 1], located at [-3 sigma, -sigma, sigma, 3 sigma]
    
    (x, v) = EV
    w = (6.0**0.5) * v**0.5
    ans = select_variance(v > 0.0, (F(x+w)-2*F(x)+F(x-w))/w**2, f(x))
    if bounds is not None:
        ans.interval = interval.interval[bounds[0], bounds[1]]
    return ans

def get_random_node(self):
    if hasattr(self, 'random'):
        return self.random
    self.random = random_uniform(0.0, 1.0)
    return self.random
    
def bandlimited_probabilistic_periodic4(self, EV, F, bounds, f):
    clip_thr = 0.25
    blend_thr = 0.5
    (x, v) = EV
    w = (6.0**0.5) * v**0.5
    a = x-w
    b = x+w
    fa = floor(a)
    fb = floor(b)
    tent_all = bandlimited_tent_functor(EV, f, F, bounds)
    p = (fb-a)/(b-a)
    select_side = p >= 0.5
    random_case = select(select_side, (F(fb)-2*F((fb+a)/2)+F(a))/(((fb-a)/2)**2), (F(b)-2*F((b+fb)/2)+F(fb))/(((b-fb)/2)**2))
    alpha = (b-a-clip_thr)/(blend_thr-clip_thr)
    interpolate_case = select(select_side, \
                              (F(alpha*b+(1-alpha)*fb)-2*F((alpha*b+(1-alpha)*fb+a)/2)+F(a))/(((alpha*b+(1-alpha)*fb-a)/2)**2), \
                              (F(b)-2*F((b+alpha*a+(1-alpha)*fb)/2)+F(alpha*a+(1-alpha)*fb))/(((b-alpha*a-(1-alpha)*fb)/2)**2))
    
    
    single_dis = select(b-a<clip_thr, random_case, interpolate_case)
    ans = select((b-a<blend_thr) * (fb > fa), single_dis, tent_all)
    if bounds is not None:
        ans.interval = interval.interval[bounds[0], bounds[1]]
    return ans

def bandlimited_box_acos(self, EV):
    def F(x):
        return x * acos(x) - (1 - x ** 2) ** 0.5
    return bandlimited_box_functor(EV, lambda x: acos(x), F, (0.0, math.pi), dist_to_singularity=lambda x: (1-abs(x)))
    
def bandlimited_box_acos2(self, EV):
    def F(x):
        f = acos(x)
        return -2*sqrt(1 - x**2)*f - x*(2 - f**2)
    return bandlimited_box_functor(EV, lambda x: acos(x)**2, F, (0.0, math.pi), dist_to_singularity=lambda x: (1-abs(x)))
    
def bandlimited_box_fract(self, EV):
    def F(x):
        return (fract(x)**2 + floor(x)) / 2.0
    if not probabilistic_fract:
        return bandlimited_box_functor(EV, lambda x: fract(x), F, (0.0, 1.0))
    else:
        if continuous_probabilistic_fract:
            return bandlimited_probabilistic_periodic2(self, EV, F, (0.0, 1.0))
        else:
            return bandlimited_probabilistic_periodic(self, EV, F, (0.0, 1.0))

def bandlimited_box_fract2(self, EV):
    def F(x):
        return (fract(x)**3 + floor(x)) / 3.0
    if not probabilistic_fract:
        return bandlimited_box_functor(EV, lambda x: fract(x)**2, F, (0.0, 1.0))
    else:
        if continuous_probabilistic_fract:
            return bandlimited_probabilistic_periodic2(self, EV, F, (0.0, 1.0))
        else:
            return bandlimited_probabilistic_periodic(self, EV, F, (0.0, 1.0))

def bandlimited_tent_fract(self, EV, use_tent=False):
    def F(x):
        fractv = fract(x)
        floorv = floor(x)
        return 0.5 * (0.5*(floorv-1)*floorv+fractv*floorv) + 1.0/6.0 * floorv + 1.0/6.0*fractv**3
    if (not probabilistic_tent_fract) or use_tent:
        return bandlimited_tent_functor(EV, lambda x: fract(x), F, (0.0, 1.0))
    else:
        return bandlimited_probabilistic_periodic4(self, EV, F, (0.0, 1.0), lambda x: fract(x))

def bandlimited_tent_fract2(self, EV, use_tent=False):
    def F(x):
        fractv = fract(x)
        floorv = floor(x)
        return 1.0/3.0*((floorv-1)*floorv/2.0 + floorv*fractv) + 1.0/12.0*floorv + 1.0/12.0*fractv**4
    if (not probabilistic_tent_fract) or use_tent:
        return bandlimited_tent_functor(EV, lambda x: fract(x)**2, F, (0.0, 1.0))
    else:
        return bandlimited_probabilistic_periodic4(self, EV, F, (0.0, 1.0), lambda x: fract(x)**2)

if tune_fract:
    probabilistic_fract = True
    
    def bandlimited_fract(self, EV, default_mode=None):
        approx_mode = getattr(self, 'approx_fract_mode', default_mode)
        if approx_mode == 'tent':
            return bandlimited_tent_fract(self, EV)
        elif approx_mode == 'probabilistic':
            return bandlimited_box_fract(self, EV)
        else:
            raise ValueError('unrecognized approx_fract_mode')
        
    def bandlimited_fract2(self, EV, default_mode=None):
        approx_mode = getattr(self, 'approx_fract_mode', default_mode)
        if approx_mode == 'tent':
            return bandlimited_tent_fract2(self, EV)
        elif approx_mode == 'probabilistic':
            return bandlimited_box_fract2(self, EV)
        else:
            raise ValueError('unrecognized approx_fract_mode')

elif allow_different_fract:
    def bandlimited_fract(self, EV):
        approx_mode = getattr(self, 'approx_fract_mode', 'probabilistic')
        if approx_mode == 'tent':
            return bandlimited_tent_fract(self, EV, True)
        else:
            return bandlimited_tent_fract(self, EV)
    
    def bandlimited_fract2(self, EV):
        approx_mode = getattr(self, 'approx_fract_mode', 'probabilistic')
        if approx_mode == 'tent':
            return bandlimited_tent_fract2(self, EV, True)
        else:
            return bandlimited_tent_fract2(self, EV)
            
else:
    if probabilistic_tent_fract:
        bandlimited_fract = bandlimited_tent_fract
        bandlimited_fract2 = bandlimited_tent_fract2
    elif fract_bandlimit == 'box' or probabilistic_fract:
        bandlimited_fract = bandlimited_box_fract
        bandlimited_fract2 = bandlimited_box_fract2
    elif fract_bandlimit == 'tent':
        bandlimited_fract = bandlimited_tent_fract
        bandlimited_fract2 = bandlimited_tent_fract2
    elif fract_bandlimit == 'sampled':
        bandlimited_fract = lambda self, EV: bandlimited_sampled(lambda x: fract(x), [EV], default_nsamples, id(self))
        bandlimited_fract2 = lambda self, EV: bandlimited_sampled(lambda x: fract(x)**2, [EV], default_nsamples, id(self))
    else:
        raise ValueError('unknown fract_bandlimit')

def bandlimited_floor(self, EV):
    x = EV[0]
    return x - bandlimited_fract(self, EV)

def bandlimited_floor2(self, EV):

    x = EV[0]
    if fract_bandlimit == 'tent':
        def F(x):
            return x**3/6
        x2_bandlimited = bandlimited_tent_functor(EV, lambda x: x, F)
    else:
        raise ValueError('unsupported fract_bandlimit')
    return x2_bandlimited - 2 * x * bandlimited_fract(self, EV) + bandlimited_fract2(self, EV)

def f_triangle_wave(x):
    T = 2.0
    xT_floor = floor(x/T)
    TxT_floor = T*floor(x/T)
    xf = x-T*xT_floor
    return min(xf, T-xf)

def bandlimited_box_triangle_wave(self, EV):
    T = 2.0
    def F(x):
        xT_floor = floor(x/T)
        xf = x-T*xT_floor
        half_x2 = 0.5*xf**2
        return xT_floor + select(xf < 1.0, half_x2, 2*xf-half_x2-1)

    return bandlimited_box_functor(EV, f_triangle_wave, F, (0.0, 1.0))

def bandlimited_box_triangle_wave2(self, EV):
    T = 2.0
    def F(x):
        xT_floor = floor(x/T)
        xf = x-T*xT_floor
        x3_term = (1.0/3.0)*xf**3
        return (2.0/3.0)*xT_floor + select(xf < 1.0, x3_term, x3_term-2*xf**2+4*xf-2)

    return bandlimited_box_functor(EV, lambda x: f_triangle_wave(x)**2, F, (0.0, 1.0))

def bandlimited_tent_triangle_wave(self, EV):
    T = 2.0
    def F(x):
        q = floor(x/T)
        v = x - T*q
        v3_term = 1.0/6.0*v**3
        Fp2 = select(v<=1.0, v3_term, -v3_term+v**2-v+1.0/3.0)
        return (T*(q-1)*q/2 + (x - T*q)*q) + q + Fp2

    return bandlimited_tent_functor(EV, f_triangle_wave, F, (0.0, 1.0))

def bandlimited_tent_triangle_wave2(self, EV):
    T = 2.0
    def F(x):
        q = floor(x/T)
        v = x - T*q
        Fp2 = select(v<=1.0, 1.0/12*v**4, 1.0/12*v**4-2.0/3*v**3+2*v**2-2*v+2.0/3)
        return (2.0/3.0)*(T*(q-1)*q/2 + (x - T*q)*q) + (2.0/3.0)*q + Fp2

    return bandlimited_tent_functor(EV, lambda x: f_triangle_wave(x)**2, F, (0.0, 1.0))

def get_gaussian_samples(arg_key, nsamples, ndims, cache={}):
    key = (arg_key, nsamples, ndims)
    if key in cache:
        return cache[key]
    N = numpy.random.normal(size=(nsamples, ndims))
    ans = N
    cache[key] = ans
    return ans

def bandlimited_sampled(f, EV_tuple, nsamples, arg_key):
    """
    Bandlimit a function at the given expected value and variance (EV) tuple, with the given number of samples.
    
    Given a function f(x1, [x2, ...]) which returns an Expr given those arguments, return an Expr that
    sums nsamples samples of f with a Gaussian distribution (EV) and divides by the sum. Here arg_key
    is used as a cache key to re-use the samples (in case one wants to use the sample samples).
    """
    ndims = len(EV_tuple)
    samples = get_gaussian_samples(arg_key, nsamples, ndims)
    samples = [[EV_tuple[j][0] + (EV_tuple[j][1]**0.5)*samples[i][j] for j in range(ndims)] for i in range(nsamples)]
    return sum(f(*sample) for sample in samples)/len(samples)

if fract_bandlimit == 'tent':
    bandlimited_triangle_wave = bandlimited_tent_triangle_wave
    bandlimited_triangle_wave2 = bandlimited_tent_triangle_wave2
elif fract_bandlimit == 'box':
    bandlimited_triangle_wave = bandlimited_box_triangle_wave
    bandlimited_triangle_wave2 = bandlimited_box_triangle_wave2
elif fract_bandlimit == 'sampled':
    bandlimited_triangle_wave = lambda self, EV: bandlimited_sampled(lambda x: triangle_wave(x), [EV], default_nsamples, id(self))
    bandlimited_triangle_wave2 = lambda self, EV: bandlimited_sampled(lambda x: triangle_wave(x)**2, [EV], default_nsamples, id(self))
else:
    raise ValueError('unknown fract_bandlimit mode')

def bandlimited_box_atan(self, EV):
    def F(x):
        return x * atan(x) - 0.5 * log(x**2+1)

    return bandlimited_box_functor(EV, lambda x: atan(x), F)

def bandlimited_box_atan_approx(self, EV):
    def F(x):
        a = sqrt(256*x**2+25*numpy.pi**2)
        b = 3 * numpy.pi * log(a + 3*numpy.pi)
        return 1.0/32.0*numpy.pi * (a - b)

    return bandlimited_box_functor(EV, lambda x: (8*x/(3+sqrt(25+((16/numpy.pi)*x)**2))), F)

def bandlimited_box_atan_approx2(self, EV):            # Not C's atan2(y, x) but rather atan(x)**2
    # Approximate atan(x) as (8*x/(3+sqrt(25+(16*x/pi)**2))), then use integration against box
    def F(x):
        a = (12*numpy.pi*sqrt(256*x**2+25*numpy.pi**2)*x) / (16*x**2 + numpy.pi**2)
        b = 36*numpy.pi**2*x / (16*x**2 + numpy.pi**2)
        c = 7*numpy.pi*atan(12*x/sqrt(256*x**2+25*numpy.pi**2))
        d = 64*x
        e = 7*numpy.pi*atan(4*x/numpy.pi)
        f = 24*numpy.pi*asinh(16*x/(5*numpy.pi))
        return (1.0/256.0 * numpy.pi**2) * (a - b + c + d - e - f)

    return bandlimited_box_functor(EV, lambda x: atan(x)**2, F)

def bandlimited_gaussian_cos4(self, EV):
    (x, v) = EV
    return 3.0/8.0 + (0.5) * cos(2*x)*exp(-2*v) + (1.0/8.0) * (cos(4*x)*exp(-8*v))

def bandlimited_gaussian_sin4(self, EV):
    (x, v) = EV
    return 3.0/8.0 - (0.5) * cos(2*x)*exp(-2*v) + (1.0/8.0) * (cos(4*x)*exp(-8*v))

def bandlimited_gaussian_exp_pow(power):
    def f(self, EV):
        (x, v) = EV
        return exp(power*x+v*(power**2/2.0))
    return f

def bandlimited_none_select():
    def f(self, EV_arg, EV1, EV2):
        return (select(EV_arg[0], EV1[0], EV2[0]),
                select(EV_arg[0], EV1[1], EV2[1]))
    return f

def bandlimited_none_max():
    def f(self, EV1, EV2):
        return (select(EV1[0]>EV2[0], EV1[0], EV2[0]),
                select(EV1[0]>EV2[0], EV1[1], EV2[1]))
    return f

def bandlimited_none_min():
    def f(self, EV1, EV2):
        return (select(EV1[0]<EV2[0], EV1[0], EV2[0]),
                select(EV1[0]<EV2[0], EV1[1], EV2[1]))
    return f

def clamp_var(var):
    min_var = 1e-20
    return max_nosmooth(var, min_var)

def expectation_variance_functor(E_func, E_squared_func):
    def f(self, EV):
        E = E_func(self, EV)
        var = E_squared_func(self, EV) - E**2
        return (E, var)
    return f

def expectation_variance_constant():
    def f(self, *args):
        return self.to_expectation_variance_const()
    return f

def printed(x):
    pprint.pprint(x)
    return x

ge0 = lambda x: sign_up(x)*0.5+0.5
gt0 = lambda x: sign_down(x)*0.5+0.5

sign = Func('our_sign',                     # Ordinarily defined sign function, with sign(0) = 0
             lambda x: (ConstExpr(0.0),),
              expectation_variance_functor(bandlimited_sign, lambda self,EV: ConstExpr(1.0)),
              lambda x: interval_sign(x[0]))

sign_down = Func('our_sign_down',           # Sign function with sign(0) => -1
            lambda x: (ConstExpr(0.0),),
            expectation_variance_functor(bandlimited_sign, lambda self,EV: ConstExpr(1.0)),
            lambda x: interval_sign(x[0]))

sign_up   = Func('our_sign_up',             # Sign function with sign(0) => +1
            lambda x: (ConstExpr(0.0),),
            expectation_variance_functor(bandlimited_sign, lambda self,EV: ConstExpr(1.0)),
            lambda x: interval_sign(x[0]))

def min(a, b):
    """Like min_nosmooth(), but can be bandlimited."""
    return a + (b-a) * (sign(a-b)*0.5+0.5)

def max(a, b):
    """Like max_nosmooth(), but can be bandlimited."""
    return a + (b-a) * (sign(b-a)*0.5+0.5)

def select_smoothed(a, b, c):
    """Like select(), but can be bandlimited. Assumes a is either zero or one."""
    return b + (c - b) * (a)

random_uniform = Func('random_uniform',
                     lambda x: None,
                     expectation_variance_constant(),
                     interval_lambda=lambda x: interval.interval[x[0], x[1]])

erf = Func('erf',
            lambda x: ((2/math.pi**0.5*exp(-(x[0])**2)),),
            interval_lambda=lambda x: interval.interval[0.0, 1.0]) 

exp = Func('exp',
            lambda x: (exp(x[0]),),
            expectation_variance_functor(bandlimited_gaussian_exp, bandlimited_gaussian_exp_pow(2)),
            lambda x: interval.imath.exp(x[0]))

cos = Func('cos',
            lambda x: (-sin(x[0]),),
            expectation_variance_functor(bandlimited_gaussian_cos, bandlimited_gaussian_cos2),
            lambda x: interval.imath.cos(x[0]))

sin = Func('sin',
            lambda x: (cos(x[0]),),
            expectation_variance_functor(bandlimited_gaussian_sin, bandlimited_gaussian_sin2),
            lambda x: interval.imath.sin(x[0]))

atan = Func('atan',
            lambda x: (1.0/((x[0])**2+1.0),))

def atan_approx_deriv(x):
    a = sqrt(256*x**2 + 25*numpy.pi**2)
    return (4*numpy.pi**2 * (a + 3.0)) / (128*x**2 + 3*numpy.pi * a + 17 * numpy.pi**2)

atan_approx = Func('atan_approx',
            lambda x: (atan_approx_deriv(x[0]),),
            expectation_variance_functor(bandlimited_box_atan_approx, bandlimited_box_atan_approx2),
            lambda x: (8*x[0]/(3+interval.imath.sqrt(25+(16*x[0]/numpy.pi)**2))))

def atan2(y, x):
    """
    atan that accepts 2 inputs, and return range is from -pi/2 to pi*3/2
    not accurate when x = 0
    """
    abs_x = max_nosmooth(abs(x), 1e-8)
    return 0.5 * (sign_up(x) + 1) * math.pi + atan_approx(sign_up(x)*y/abs_x)

def acos_approx(x):
    """
    handles out of buonds by calmping to either 1 or -1
    """
    x_value = max_nosmooth(min_nosmooth(x, 1.0), -1.0)
    return acos(x_value)

def acos_deriv(x):
    return - (1 - x ** 2) ** -0.5

acos = Func('acos', 
            lambda x: (acos_deriv(x[0]),),
            expectation_variance_functor(bandlimited_box_acos, bandlimited_box_acos2),
            lambda x: interval.interval[0.0, math.pi])

floor = Func('floor',
            lambda x: (0.0,),
            expectation_variance_functor(bandlimited_floor, bandlimited_floor2)) # TODO: implement interval

fract = Func('fract',
             lambda x: (1.0,),
             expectation_variance_functor(bandlimited_fract, bandlimited_fract2),
             lambda x: interval.interval[0.0, 1.0])

fract_nosmooth = Func('fract',
             lambda x: (1.0,),
             lambda self, EV: (fract(EV[0]), EV[1]),
             lambda x: interval.interval[0.0, 1.0])

triangle_wave = Func('triangle_wave',
                     lambda x: (select(x%2<1.0, 1.0, -1.0),),
                     expectation_variance_functor(bandlimited_triangle_wave, bandlimited_triangle_wave2),
                     lambda x: interval.interval[0.0, 1.0])

asinh = Func('asinh',
             lambda x: (1.0/sqrt((x[0])**2+1.0),),
             interval_lambda=lambda x: interval.imath.log(x[0]+interval.imath.sqrt(1+x[0]**2)))

def gabor_expectation_variance(self, EV_K, EV_a, EV_F, EV_omega, EV_impulses, EV_period, EV_x, EV_y):
    E = filtered_gabor_noise(EV_K[0], EV_a[0], EV_F[0], EV_omega[0], EV_impulses[0], EV_period[0], EV_x[0], EV_y[0], EV_x[1], EV_y[1])
    var = filtered_gabor_noise_variance(EV_K[0], EV_a[0], EV_F[0], EV_omega[0], EV_impulses[0], EV_period[0], EV_x[0], EV_y[0], EV_x[1], EV_y[1])
    return (E, var)
             
gabor_noise = Func('gabor_noise',
                   lambda x: None, # Not implemented
                   gabor_expectation_variance,
                   lambda x: interval.interval[-x[0], x[0]])

filtered_gabor_noise = Func('filtered_gabor_noise',
                            lambda x: None) # Not implemented     

filtered_gabor_noise_variance = Func('filtered_gabor_noise_variance',
                                     lambda x: None) # Not implemented
             
# A select() that can be smoothed
select = lambda a, b, c: a*b + (1-a)*c

# A select() that is never smoothed: semantics are the same as an if statement (differing from Heaviside step)
select_nosmooth = Func('our_select',
            lambda x: (ConstExpr(0.0), select(x[0], 1.0, 0.0), select(x[0], 0.0, 1.0)),
            bandlimited_none_select(),
            interval_lambda=lambda x: x[1]|x[2],
            allows_approx_bool=False)

sqrt = lambda arg: arg**0.5
log = Func('log',
            lambda x: (1.0/x[0],),
            interval_lambda=lambda x: interval.imath.log(x[0]))

# Like min(), but never smoothed
min_nosmooth = Func('min',
            lambda x: (select(x[0]<x[1], 1.0, 0.0), select(x[0]<x[1], 0.0, 1.0)),
            bandlimited_none_min(),
            interval_lambda=lambda x: x[0] | x[1])

# Like max(), but never smoothed
max_nosmooth = Func('max',
            lambda x: (select(x[0]>x[1], 1.0, 0.0), select(x[0]>x[1], 0.0, 1.0)),
            bandlimited_none_max(),
            interval_lambda=lambda x: x[0] | x[1])

random_matrix = Func('MatrixXd::Random', lambda x: None,
            expectation_variance_constant(),
            interval_lambda=lambda x: interval.interval[0, 1])

gaussian_random = Func('Gaussian_RNG::get', lambda x: None,
                    expectation_variance_constant())
                    #interval_lambda=lambda x: interval.interval[-5, 5])

advance_gaussian_random = Func('Gaussian_RNG::advance', lambda x: None)

load_faces = Func('load_faces', lambda x: None)
load_txt = Func('load_txt', lambda x:None)

# Bandlimiting of higher powers of above functions

func_powers = {}

for pow_arg in range(2, 11):
    func_powers[('exp', pow_arg)] = expectation_variance_functor(bandlimited_gaussian_exp_pow(pow_arg),
                                                                 bandlimited_gaussian_exp_pow(pow_arg*2))
func_powers[('cos', 2)] = expectation_variance_functor(bandlimited_gaussian_cos2, bandlimited_gaussian_cos4)
func_powers[('sin', 2)] = expectation_variance_functor(bandlimited_gaussian_sin2, bandlimited_gaussian_sin4)

def get_channel(a, b):
    if a.channel is not None:
        if b.channel is not None:
            if a.channel == b.channel:
                return a.channel
            else:
                return None
        else:
            return a.channel
    else:
        return b.channel
